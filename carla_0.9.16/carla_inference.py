#!/usr/bin/env python
# coding=utf-8
'''
ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-11-25
è¯´æ˜: Carlaè‡ªåŠ¨é©¾é©¶æ¨¡å‹å®æ—¶æ¨ç†è„šæœ¬ï¼ˆæ¨¡å—åŒ–ç‰ˆæœ¬ï¼‰
      ä»Carlaå®æ—¶è·å–å›¾åƒå’Œé€Ÿåº¦ï¼Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹æ§åˆ¶ä¿¡å·ï¼Œå¹¶æ§åˆ¶è½¦è¾†
'''

import os
import sys
import time
import argparse

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸ºUTF-8ï¼Œé¿å…Windowsä¸‹çš„ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import torch
import numpy as np
import cv2
import carla

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from carla_config import *
from carla_sensors import SensorManager
from carla_visualizer import CarlaVisualizer

# å¯è§†åŒ–æ¨¡å¼å¸¸é‡
VIS_MODE_SPECTATOR = 'spectator'  # Spectatorè·Ÿéšæ¨¡å¼ï¼ˆåœ¨CARLAçª—å£ä¸­æ˜¾ç¤ºï¼‰
VIS_MODE_OPENCV = 'opencv'        # OpenCVç‹¬ç«‹çª—å£æ¨¡å¼ï¼ˆæ—§æ¨¡å¼ï¼‰
from navigation_planner_adapter import NavigationPlannerAdapter
from carla_model_loader import ModelLoader
from carla_image_processor import ImageProcessor
from carla_vehicle_controller import VehicleController
from carla_model_predictor import ModelPredictor
from carla_vehicle_spawner import VehicleSpawner
from carla_npc_manager import NPCManager, NPCConfig

# å¯è§£é‡Šæ€§æ¨¡å—ï¼ˆå¯é€‰ï¼‰
try:
    from carla_interpretability import (
        InterpretabilityVisualizer, 
        GradCAM, 
        BrakeAnalyzer,
        create_interpretability_visualizer
    )
    INTERPRETABILITY_AVAILABLE = True
except ImportError:
    INTERPRETABILITY_AVAILABLE = False
    print("âš ï¸ å¯è§£é‡Šæ€§æ¨¡å—æœªæ‰¾åˆ°ï¼Œ--interpret åŠŸèƒ½ä¸å¯ç”¨")


class CarlaInference:
    """
    Carlaè‡ªåŠ¨é©¾é©¶æ¨ç†ç±»ï¼ˆæ¨¡å—åŒ–ç‰ˆæœ¬ï¼‰
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. è¿æ¥åˆ°CarlaæœåŠ¡å™¨
    2. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    3. å®æ—¶è·å–ä¼ æ„Ÿå™¨æ•°æ®
    4. ä½¿ç”¨æ¨¡å‹é¢„æµ‹æ§åˆ¶ä¿¡å·
    5. æ§åˆ¶è½¦è¾†è¡Œé©¶
    """
    
    def __init__(self, 
                 model_path,
                 host='localhost',
                 port=2000,
                 town='Town01',
                 gpu_id=0,
                 enable_post_processing=False,
                 post_processor_config=None,
                 enable_image_crop=True,
                 visualization_mode='spectator',
                 npc_config=None,
                 weather='ClearNoon',
                 enable_interpretability=False,
                 interpret_save_dir=None,
                 interpret_save_interval=10,
                 interpret_device='gpu',
                 interpret_full_analysis=True,
                 interpret_row1_layer=-3,
                 interpret_row2_layers=None,
                 interpret_ig_steps=30):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        å‚æ•°:
            model_path (str): è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„
            host (str): CarlaæœåŠ¡å™¨åœ°å€
            port (int): CarlaæœåŠ¡å™¨ç«¯å£
            town (str): åœ°å›¾åç§°
            gpu_id (int): GPU IDï¼Œ-1è¡¨ç¤ºä½¿ç”¨CPU
            enable_post_processing (bool): æ˜¯å¦å¯ç”¨åå¤„ç†
            post_processor_config (dict): åå¤„ç†å™¨é…ç½®
            enable_image_crop (bool): æ˜¯å¦å¯ç”¨å›¾åƒè£å‰ªï¼ˆå»é™¤å¤©ç©ºå’Œå¼•æ“ç›–ï¼‰
            visualization_mode (str): å¯è§†åŒ–æ¨¡å¼
                - 'spectator': Spectatorè·Ÿéšæ¨¡å¼ï¼ˆåœ¨CARLA UE4çª—å£ä¸­ç¬¬ä¸‰äººç§°è·Ÿéšï¼‰
                - 'opencv': OpenCVç‹¬ç«‹çª—å£æ¨¡å¼ï¼ˆæ—§æ¨¡å¼ï¼Œå°å¼¹çª—ï¼‰
            npc_config (NPCConfig): NPCé…ç½®ï¼ŒNoneè¡¨ç¤ºä¸ç”ŸæˆNPC
            weather (str): å¤©æ°”é¢„è®¾åç§°ï¼Œæ”¯æŒ:
                - ClearNoon, ClearSunset
                - CloudyNoon, CloudySunset
                - WetNoon, WetSunset
                - WetCloudyNoon, WetCloudySunset
                - HardRainNoon, HardRainSunset
                - SoftRainNoon, SoftRainSunset
            interpret_row1_layer (int): ç¬¬ä¸€è¡Œçƒ­åŠ›å›¾ä½¿ç”¨çš„å·ç§¯å±‚ç´¢å¼•
            interpret_row2_layers (list): ç¬¬äºŒè¡Œå¤šå±‚çº§çƒ­åŠ›å›¾ä½¿ç”¨çš„å·ç§¯å±‚ç´¢å¼•åˆ—è¡¨
            interpret_ig_steps (int): ç§¯åˆ†æ¢¯åº¦çš„ç§¯åˆ†æ­¥æ•°
        """
        # Carlaè¿æ¥å‚æ•°
        self.host = host
        self.port = port
        self.town = town
        self.weather = weather
        
        # è®¾å¤‡é…ç½®
        self.gpu_id = gpu_id
        self.device = torch.device(
            f'cuda:{gpu_id}' if gpu_id >= 0 and torch.cuda.is_available() else 'cpu'
        )
        
        # Carlaå¯¹è±¡
        self.client = None
        self.world = None
        self.vehicle = None
        
        # åŠŸèƒ½æ¨¡å—
        self.model_loader = ModelLoader(model_path, self.device)
        # å›¾åƒå¤„ç†å™¨ï¼ˆä¸æ•°æ®æ”¶é›†ä¿æŒä¸€è‡´çš„è£å‰ªå‚æ•°ï¼‰
        # è£å‰ªåŒºåŸŸï¼š[90:485, :] å»é™¤å¤©ç©ºå’Œè½¦å¤´
        self.image_processor = ImageProcessor(
            self.device,
            enable_crop=enable_image_crop,
            crop_top=90,
            crop_bottom=485
        )
        self.vehicle_controller = VehicleController()
        self.model_predictor = None  # åœ¨åŠ è½½æ¨¡å‹ååˆå§‹åŒ–
        self.vehicle_spawner = None  # åœ¨è¿æ¥Carlaååˆå§‹åŒ–
        
        # åå¤„ç†å™¨é…ç½®
        self.enable_post_processing = enable_post_processing
        self.post_processor_config = post_processor_config
        
        # å¯è§†åŒ–æ¨¡å¼
        self.visualization_mode = visualization_mode
        
        # NPCé…ç½®
        self.npc_config = npc_config
        self.npc_manager = None
        
        # ç»„ä»¶æ¨¡å—
        self.sensor_manager = None
        self.navigation_planner = None
        self.visualizer = CarlaVisualizer(mode=visualization_mode)
        
        # çŠ¶æ€
        self.current_command = 2  # é»˜è®¤å‘½ä»¤ï¼š2=è·Ÿè½¦
        self.frame_count = 0
        self.total_inference_time = 0.0
        
        # å¯è§£é‡Šæ€§æ¨¡å—
        self.enable_interpretability = enable_interpretability and INTERPRETABILITY_AVAILABLE
        self.interpret_save_dir = interpret_save_dir
        self.interpret_save_interval = interpret_save_interval  # ä»ªè¡¨æ¿ä¿å­˜é¢‘ç‡ï¼ˆæ¯Nå¸§ä¿å­˜ä¸€æ¬¡ï¼Œ0è¡¨ç¤ºä¸è‡ªåŠ¨ä¿å­˜ï¼‰
        self.interpret_device = interpret_device  # å¯è§£é‡Šæ€§åˆ†æè®¾å¤‡: 'gpu' æˆ– 'cpu'
        self.interpret_full_analysis = interpret_full_analysis  # æ˜¯å¦å¯ç”¨å®Œæ•´åˆ†æ
        self.interpret_row1_layer = interpret_row1_layer  # ç¬¬ä¸€è¡Œçƒ­åŠ›å›¾å·ç§¯å±‚ç´¢å¼•
        self.interpret_row2_layers = interpret_row2_layers if interpret_row2_layers else [-1, -3, -5]  # ç¬¬äºŒè¡Œå¤šå±‚çº§çƒ­åŠ›å›¾å·ç§¯å±‚ç´¢å¼•
        self.interpret_ig_steps = interpret_ig_steps  # ç§¯åˆ†æ¢¯åº¦æ­¥æ•°
        self.interp_visualizer = None
        self.grad_cam = None
        self.brake_analyzer = None
        
        # è®¾ç½®å¯è§£é‡Šæ€§åˆ†æçš„è®¾å¤‡
        if interpret_device == 'cpu':
            self.interp_compute_device = torch.device('cpu')
        else:
            self.interp_compute_device = self.device  # ä¸æ¨¡å‹æ¨ç†ä½¿ç”¨åŒä¸€è®¾å¤‡
        
        print(f"åˆå§‹åŒ–æ¨ç†å™¨ - è®¾å¤‡: {self.device}")
        if self.enable_interpretability:
            print(f"âœ… å¯è§£é‡Šæ€§å¯è§†åŒ–å·²å¯ç”¨")
            print(f"   - åˆ†æè®¾å¤‡: {self.interp_compute_device}")
            print(f"   - å®Œæ•´åˆ†æ: {'æ˜¯' if interpret_full_analysis else 'å¦ (ä»…Grad-CAM)'}")
            print(f"   - ç¬¬ä¸€è¡Œçƒ­åŠ›å›¾å±‚ç´¢å¼•: {self.interpret_row1_layer}")
            print(f"   - ç¬¬äºŒè¡Œå¤šå±‚ç´¢å¼•: {self.interpret_row2_layers}")
            print(f"   - ç§¯åˆ†æ¢¯åº¦æ­¥æ•°: {self.interpret_ig_steps}")
        
    def load_model(self, net_structure=2):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        self.model_loader.net_structure = net_structure
        model = self.model_loader.load()
        self.model_predictor = ModelPredictor(
            model, 
            self.device,
            enable_post_processing=self.enable_post_processing,
            post_processor_config=self.post_processor_config
        )
        
        # åˆå§‹åŒ–å¯è§£é‡Šæ€§å·¥å…·ï¼ˆå­¦æœ¯ä¸¥è°¨ç‰ˆï¼‰
        if self.enable_interpretability:
            # ä½¿ç”¨æ–°çš„ç»¼åˆåˆ†æå™¨ï¼Œæ”¯æŒé€‰æ‹©è®¡ç®—è®¾å¤‡å’Œçƒ­åŠ›å›¾å±‚é…ç½®
            self.interp_visualizer = create_interpretability_visualizer(
                model, self.interp_compute_device, self.interpret_save_dir,
                full_analysis=self.interpret_full_analysis,  # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦å¯ç”¨å®Œæ•´åˆ†æ
                grad_cam_layer_index=self.interpret_row1_layer,  # ç¬¬ä¸€è¡Œçƒ­åŠ›å›¾å±‚ç´¢å¼•
                multi_layer_indices=self.interpret_row2_layers,  # ç¬¬äºŒè¡Œå¤šå±‚çº§çƒ­åŠ›å›¾å±‚ç´¢å¼•
                ig_steps=self.interpret_ig_steps  # ç§¯åˆ†æ¢¯åº¦æ­¥æ•°
            )
            # ä¿ç•™æ—§æ¥å£å…¼å®¹æ€§
            self.grad_cam = self.interp_visualizer.grad_cam
            self.brake_analyzer = self.interp_visualizer.brake_analyzer
            
            if self.interpret_full_analysis:
                print("âœ… å­¦æœ¯ä¸¥è°¨ç‰ˆå¯è§£é‡Šæ€§åˆ†æå™¨å·²åˆå§‹åŒ–")
                print("   åŒ…å«: Grad-CAM, é®æŒ¡æ•æ„Ÿæ€§, ç§¯åˆ†æ¢¯åº¦, åˆ é™¤/æ’å…¥æ›²çº¿")
            else:
                print("âœ… è½»é‡çº§å¯è§£é‡Šæ€§åˆ†æå™¨å·²åˆå§‹åŒ–")
                print("   åŒ…å«: Grad-CAM (é«˜è®¡ç®—é‡æ–¹æ³•å·²ç¦ç”¨)")
            print(f"   è®¡ç®—è®¾å¤‡: {self.interp_compute_device}")
        
    def connect_carla(self):
        """è¿æ¥åˆ°CarlaæœåŠ¡å™¨"""
        print(f"æ­£åœ¨è¿æ¥åˆ°CarlaæœåŠ¡å™¨ {self.host}:{self.port}...")
        
        self.client = carla.Client(self.host, self.port)
        self.client.set_timeout(10.0)
        
        print(f"æ­£åœ¨åŠ è½½åœ°å›¾ {self.town}...")
        self.world = self.client.load_world(self.town)
        
        # è®¾ç½®å¤©æ°”
        self._set_weather()
        
        # è®¾ç½®åŒæ­¥æ¨¡å¼
        settings = self.world.get_settings()
        settings.synchronous_mode = True
        settings.fixed_delta_seconds = SYNC_MODE_DELTA_SECONDS
        self.world.apply_settings(settings)
        
        # åˆå§‹åŒ–è½¦è¾†ç”Ÿæˆå™¨
        self.vehicle_spawner = VehicleSpawner(self.world)
        
        # åˆ›å»ºå¯¼èˆªè§„åˆ’å™¨
        print("æ­£åœ¨åˆå§‹åŒ–å¯¼èˆªè§„åˆ’å™¨...")
        self.navigation_planner = NavigationPlannerAdapter(
            self.world, 
            sampling_resolution=ROUTE_SAMPLING_RESOLUTION
        )
        
        # ç”ŸæˆNPCï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if self.npc_config is not None:
            self._spawn_npcs()
        
        print("æˆåŠŸè¿æ¥åˆ°CarlaæœåŠ¡å™¨ï¼")
    
    def _set_weather(self):
        """è®¾ç½®å¤©æ°”"""
        if self.weather is None:
            return
            
        if hasattr(carla.WeatherParameters, self.weather):
            weather_params = getattr(carla.WeatherParameters, self.weather)
            self.world.set_weather(weather_params)
            print(f"å¤©æ°”è®¾ç½®ä¸º: {self.weather}")
        else:
            print(f"âš ï¸ æœªçŸ¥çš„å¤©æ°”é¢„è®¾: {self.weather}ï¼Œä½¿ç”¨é»˜è®¤å¤©æ°”")
            print(f"   æ”¯æŒçš„é¢„è®¾: ClearNoon, ClearSunset, CloudyNoon, CloudySunset, "
                  f"WetNoon, WetSunset, WetCloudyNoon, WetCloudySunset, "
                  f"HardRainNoon, HardRainSunset, SoftRainNoon, SoftRainSunset")
    
    def _spawn_npcs(self):
        """ç”ŸæˆNPCè½¦è¾†å’Œè¡Œäºº"""
        if self.npc_config is None:
            return
        
        print("\næ­£åœ¨ç”ŸæˆNPC...")
        self.npc_manager = NPCManager(self.client, self.world)
        stats = self.npc_manager.spawn_all(self.npc_config)
        print(f"NPCç”Ÿæˆå®Œæˆ: {stats['vehicles_spawned']} è¾†è½¦, {stats['walkers_spawned']} ä¸ªè¡Œäºº\n")
        
    def spawn_vehicle(self, vehicle_filter='vehicle.tesla.model3', 
                      spawn_index=None, destination_index=None, max_retries=5):
        """
        ç”Ÿæˆè½¦è¾†å¹¶è®¾ç½®è·¯çº¿
        
        å‚æ•°:
            vehicle_filter (str): è½¦è¾†ç±»å‹
            spawn_index (int): èµ·ç‚¹ç´¢å¼•ï¼ŒNoneè¡¨ç¤ºéšæœº
            destination_index (int): ç»ˆç‚¹ç´¢å¼•ï¼ŒNoneè¡¨ç¤ºéšæœº
            max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        # ç”Ÿæˆè½¦è¾†
        self.vehicle = self.vehicle_spawner.spawn(vehicle_filter, spawn_index)
        
        # åˆ›å»ºä¼ æ„Ÿå™¨ç®¡ç†å™¨
        self.sensor_manager = SensorManager(self.world, self.vehicle)
        
        # ç­‰å¾…ä¼ æ„Ÿå™¨åˆå§‹åŒ–
        for _ in range(3):
            self.world.tick()
        
        # è®¾ç½®ç›®çš„åœ°
        self._setup_destination(destination_index)
        
        # å¦‚æœæ˜¯spectatoræ¨¡å¼ï¼Œè®¾ç½®è·Ÿéš
        if self.visualization_mode == VIS_MODE_SPECTATOR:
            self.visualizer.setup_spectator_mode(self.world, self.vehicle)
            # åˆå§‹åŒ–è·¯ç½‘æ•°æ®ï¼ˆç”¨äºå¯¼èˆªåœ°å›¾æ˜¾ç¤ºå‘¨å›´é“è·¯ï¼‰
            self.visualizer.init_road_network(self.world)
        
        return True
    
    def _setup_destination(self, destination_index):
        """è®¾ç½®ç›®çš„åœ°"""
        print("\næ­£åœ¨è§„åˆ’è·¯çº¿...")
        spawn_points = self.world.get_map().get_spawn_points()
        
        if destination_index is not None and 0 <= destination_index < len(spawn_points):
            destination = spawn_points[destination_index].location
            print(f"ä½¿ç”¨æŒ‡å®šç»ˆç‚¹ç´¢å¼•: {destination_index}")
            if not self.navigation_planner.set_destination(self.vehicle, destination):
                print("âš ï¸ è­¦å‘Šï¼šæ— æ³•è§„åˆ’åˆ°æŒ‡å®šç»ˆç‚¹ï¼Œå°†ä½¿ç”¨éšæœºç›®çš„åœ°")
                self.navigation_planner.set_random_destination(self.vehicle)
        else:
            print("ä½¿ç”¨éšæœºç»ˆç‚¹")
            if not self.navigation_planner.set_random_destination(self.vehicle):
                print("âš ï¸ è­¦å‘Šï¼šæ— æ³•è§„åˆ’è·¯çº¿ï¼Œå°†ä½¿ç”¨é»˜è®¤å‘½ä»¤ï¼ˆè·Ÿè½¦ï¼‰")
        
        # å°†è·¯çº¿æ•°æ®ä¼ é€’ç»™å¯è§†åŒ–å™¨ï¼ˆç”¨äºè·¯çº¿å›¾æ˜¾ç¤ºï¼‰
        self._update_visualizer_route()
        print()
    
    def _update_visualizer_route(self):
        """æ›´æ–°å¯è§†åŒ–å™¨çš„è·¯çº¿æ•°æ®"""
        if self.navigation_planner is not None and hasattr(self.navigation_planner, '_route'):
            route = self.navigation_planner._route
            if route:
                self.visualizer.set_route(route)
                print(f"âœ… è·¯çº¿å›¾å·²æ›´æ–°ï¼ˆ{len(route)} ä¸ªè·¯ç‚¹ï¼‰")
        
    def setup_sensors(self):
        """è®¾ç½®æ‰€æœ‰ä¼ æ„Ÿå™¨"""
        self.sensor_manager.setup_camera()
        
    def run_inference(self, duration=60, visualize=True, auto_replan=True):
        """
        è¿è¡Œå®æ—¶æ¨ç†
        
        å‚æ•°:
            duration (int): è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ-1è¡¨ç¤ºæ— é™è¿è¡Œ
            visualize (bool): æ˜¯å¦æ˜¾ç¤ºå¯è§†åŒ–çª—å£
            auto_replan (bool): åˆ°è¾¾ç›®çš„åœ°åæ˜¯å¦è‡ªåŠ¨é‡æ–°è§„åˆ’è·¯çº¿
        """
        print(f"\n{'='*60}")
        print("å¼€å§‹å®æ—¶æ¨ç†æ§åˆ¶")
        print(f"{'='*60}")
        print(f"è¿è¡Œæ—¶é•¿: {'æ— é™' if duration < 0 else f'{duration}ç§’'}")
        print(f"å¯è§†åŒ–: {'å¼€å¯' if visualize else 'å…³é—­'}")
        if visualize:
            mode_desc = "Spectatorè·Ÿéšæ¨¡å¼ï¼ˆCARLAçª—å£ç¬¬ä¸‰äººç§°è§†è§’ï¼‰" if self.visualization_mode == VIS_MODE_SPECTATOR else "OpenCVç‹¬ç«‹çª—å£æ¨¡å¼"
            print(f"å¯è§†åŒ–æ¨¡å¼: {mode_desc}")
        print(f"è‡ªåŠ¨é‡æ–°è§„åˆ’: {'å¼€å¯' if auto_replan else 'å…³é—­'}")
        print(f"ç›®æ ‡å¸§ç‡: {1.0/SYNC_MODE_DELTA_SECONDS:.0f} FPS (ä¸æ¨¡æ‹Ÿæ—¶é—´åŒæ­¥)")
        print("æ¨¡å‹è¾“å‡º: ç›´æ¥æ§åˆ¶ï¼ˆæ— åå¤„ç†ï¼‰")
        if self.enable_interpretability:
            print("ğŸ” å¯è§£é‡Šæ€§å¯è§†åŒ–: å·²å¯ç”¨ (æŒ‰ 'i' åˆ‡æ¢æ˜¾ç¤º)")
        print(f"{'='*60}\n")
        
        # å¯è§£é‡Šæ€§çª—å£ï¼ˆå­¦æœ¯ä¸¥è°¨ç‰ˆï¼‰
        show_interpretability = self.enable_interpretability
        if self.enable_interpretability:
            cv2.namedWindow('Model Interpretability', cv2.WINDOW_NORMAL)
            cv2.resizeWindow('Model Interpretability', 2560, 1440)  # 2Kåˆ†è¾¨ç‡
        
        # ç­‰å¾…æ‘„åƒå¤´æ•°æ®
        print("ç­‰å¾…æ‘„åƒå¤´æ•°æ®...")
        while not self.sensor_manager.has_image():
            self.world.tick()
            time.sleep(0.01)
        print("æ‘„åƒå¤´æ•°æ®å°±ç»ªï¼\n")
        
        start_time = time.time()
        self.visualizer.set_start_time(start_time)
        self.frame_count = 0
        
        # å¸§ç‡æ§åˆ¶ï¼šç¡®ä¿æ¨¡æ‹Ÿæ—¶é—´ä¸ç°å®æ—¶é—´åŒæ­¥
        target_frame_time = SYNC_MODE_DELTA_SECONDS  # æ¯å¸§ç›®æ ‡è€—æ—¶ï¼ˆç§’ï¼‰
        
        try:
            while True:
                frame_start_time = time.time()  # è®°å½•å¸§å¼€å§‹æ—¶é—´
                
                # æ£€æŸ¥è¶…æ—¶
                if duration > 0 and time.time() - start_time > duration:
                    print(f"\nå·²è¿è¡Œ {duration} ç§’ï¼Œåœæ­¢æ¨ç†")
                    break
                
                # æ¨è¿›æ¨¡æ‹Ÿ
                self.world.tick()
                
                if not self.sensor_manager.has_image():
                    continue
                
                # ã€é‡è¦ã€‘è°ƒç”¨ run_step æ›´æ–° LocalPlanner çŠ¶æ€
                # è¿™æ · target_road_option æ‰ä¼šæ­£ç¡®æ›´æ–°
                self.navigation_planner.run_step()
                
                # è·å–å¯¼èˆªå‘½ä»¤ï¼ˆç°åœ¨ä½¿ç”¨ä¸æ•°æ®æ”¶é›†ä¸€è‡´çš„æ–¹å¼ï¼‰
                self.current_command = self.navigation_planner.get_navigation_command(self.vehicle)
                
                # è°ƒè¯•ï¼šæ‰“å°å‘½ä»¤ä¿¡æ¯
                if self.frame_count % PRINT_INTERVAL_FRAMES == 0:
                    route_info = self.navigation_planner.get_route_info(self.vehicle)
                    print(f"[DEBUG] Cmd: {self.current_command} "
                          f"({COMMAND_NAMES_EN.get(self.current_command, 'Unknown')}), "
                          f"Branch: {self.current_command - 2}")
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾
                if self.navigation_planner.is_route_completed(self.vehicle):
                    print("\nğŸ¯ å·²åˆ°è¾¾ç›®çš„åœ°ï¼")
                    if auto_replan:
                        print("æ­£åœ¨é‡æ–°è§„åˆ’è·¯çº¿...")
                        if self.navigation_planner.set_random_destination(self.vehicle):
                            # æ›´æ–°å¯è§†åŒ–å™¨çš„è·¯çº¿æ•°æ®
                            self._update_visualizer_route()
                            print("æ–°è·¯çº¿è§„åˆ’æˆåŠŸï¼Œç»§ç»­è¡Œé©¶\n")
                        else:
                            print("âš ï¸ æ— æ³•è§„åˆ’æ–°è·¯çº¿ï¼Œåœæ­¢æ¨ç†\n")
                            break
                    else:
                        print("åœæ­¢æ¨ç†\n")
                        break
                
                # è·å–æ•°æ®
                current_image = self.sensor_manager.get_latest_image()
                # æ³¨æ„ï¼šget_speed_normalized é»˜è®¤å·²ä½¿ç”¨25 KM/Hï¼Œä¸è®­ç»ƒé…ç½®ä¸€è‡´
                current_speed = self.vehicle_controller.get_speed_normalized(
                    self.vehicle, SPEED_NORMALIZATION_MPS
                )
                
                # é¢„å¤„ç†å›¾åƒ
                img_tensor = self.image_processor.preprocess(current_image)
                
                # é¢„æµ‹æ§åˆ¶
                control_result = self.model_predictor.predict(
                    img_tensor, current_speed, self.current_command
                )
                
                # ç´¯è®¡æ¨ç†æ—¶é—´
                self.total_inference_time += control_result['inference_time']
                
                # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰åˆ†æ”¯çš„é¢„æµ‹å€¼
                if self.frame_count % PRINT_INTERVAL_FRAMES == 0:
                    self._debug_print_all_branches(control_result)
                
                # åº”ç”¨æ§åˆ¶
                self.vehicle_controller.apply_control(
                    self.vehicle,
                    control_result['steer'],
                    control_result['throttle'],
                    control_result['brake']
                )
                
                # æ›´æ–°è®¡æ•°
                self.frame_count += 1
                
                # æ‰“å°ä¿¡æ¯
                if self.frame_count % PRINT_INTERVAL_FRAMES == 0:
                    self._print_status(start_time, current_speed, control_result)
                
                # è·å–æ¨¡å‹å®é™…çœ‹åˆ°çš„å›¾åƒï¼ˆè£å‰ª+ç¼©æ”¾åçš„ 200x88ï¼‰
                model_input_image = self.image_processor.get_processed_image(current_image)
                
                # å¯è§†åŒ–
                if visualize:
                    route_info = self.navigation_planner.get_route_info(self.vehicle)
                    
                    # è·å–è½¦è¾†ä½ç½®å’Œæœå‘ï¼ˆç”¨äºè·¯çº¿å›¾ï¼‰
                    vehicle_transform = self.vehicle.get_transform()
                    vehicle_location = (vehicle_transform.location.x, vehicle_transform.location.y)
                    vehicle_yaw = vehicle_transform.rotation.yaw
                    current_waypoint_index = self.navigation_planner._current_waypoint_index
                    
                    self.visualizer.visualize(
                        model_input_image, 
                        control_result, 
                        current_speed, 
                        route_info,
                        self.frame_count,
                        vehicle_location=vehicle_location,
                        vehicle_yaw=vehicle_yaw,
                        current_waypoint_index=current_waypoint_index
                    )
                
                # å¯è§£é‡Šæ€§å¯è§†åŒ–
                if self.enable_interpretability and show_interpretability:
                    # å°†å¼ é‡ç§»åˆ°å¯è§£é‡Šæ€§åˆ†æè®¾å¤‡ä¸Š
                    img_tensor_interp = img_tensor.to(self.interp_compute_device)
                    speed_tensor_interp = torch.FloatTensor([[current_speed]]).to(self.interp_compute_device)
                    interp_dashboard = self._create_interpretability_dashboard(
                        img_tensor_interp, speed_tensor_interp, model_input_image, 
                        control_result, current_speed
                    )
                    cv2.imshow('Model Interpretability', interp_dashboard)
                    
                    # è‡ªåŠ¨ä¿å­˜ä»ªè¡¨æ¿ï¼ˆæŒ‰è®¾å®šé¢‘ç‡ä¿å­˜ï¼Œ0è¡¨ç¤ºä¸è‡ªåŠ¨ä¿å­˜ï¼‰
                    if (self.interpret_save_dir is not None and 
                        self.interpret_save_interval > 0 and 
                        self.frame_count % self.interpret_save_interval == 0):
                        save_path = os.path.join(self.interpret_save_dir, f"dashboard_{self.frame_count:06d}.png")
                        cv2.imwrite(save_path, interp_dashboard)
                
                # é”®ç›˜å¤„ç†
                key = cv2.waitKey(1) & 0xFF
                if key == ord('i') and self.enable_interpretability:
                    show_interpretability = not show_interpretability
                    if show_interpretability:
                        print("ğŸ” å¯è§£é‡Šæ€§çª—å£: æ˜¾ç¤º")
                    else:
                        print("ğŸ” å¯è§£é‡Šæ€§çª—å£: éšè—")
                        cv2.destroyWindow('Model Interpretability')
                        cv2.namedWindow('Model Interpretability', cv2.WINDOW_NORMAL)
                elif key == ord('s') and self.enable_interpretability:
                    # æ‰‹åŠ¨ä¿å­˜å½“å‰å¸§
                    self._save_interpretability_frame(model_input_image, control_result)
                elif key == ord('p') and self.enable_interpretability:
                    # æ‰“å°åˆ¹è½¦ç»Ÿè®¡
                    self._print_brake_statistics()
                
                # å¸§ç‡æ§åˆ¶ï¼šç­‰å¾…åˆ°ç›®æ ‡å¸§æ—¶é—´ï¼Œç¡®ä¿æ¨¡æ‹Ÿæ—¶é—´ä¸ç°å®æ—¶é—´1:1åŒæ­¥
                frame_elapsed = time.time() - frame_start_time
                sleep_time = target_frame_time - frame_elapsed
                if sleep_time > 0:
                    time.sleep(sleep_time)
                    
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­æ¨ç†")
            
        finally:
            if visualize:
                self.visualizer.close()
            if self.enable_interpretability:
                cv2.destroyAllWindows()
                self._print_brake_statistics()
                
    def _create_interpretability_dashboard(self, img_tensor, speed_tensor, 
                                            original_image, control_result, current_speed):
        """
        åˆ›å»ºå¯è§£é‡Šæ€§ä»ªè¡¨æ¿ï¼ˆå­¦æœ¯ä¸¥è°¨ç‰ˆï¼‰
        
        ä½¿ç”¨æ–°çš„ç»¼åˆåˆ†æå™¨ï¼ŒåŒ…å«ï¼š
        - Grad-CAM çƒ­åŠ›å›¾ï¼ˆå®šæ€§ï¼‰
        - é®æŒ¡æ•æ„Ÿæ€§åˆ†æï¼ˆå®šé‡ï¼‰
        - ç§¯åˆ†æ¢¯åº¦ï¼ˆå®šé‡ï¼‰
        - åˆ é™¤/æ’å…¥æ›²çº¿ï¼ˆå®šé‡ï¼‰
        
        åªæ˜¾ç¤ºå½“å‰é€‰ä¸­åˆ†æ”¯çš„å¯è§†åŒ–ç»“æœã€‚
        """
        # æ·»åŠ é€Ÿåº¦ä¿¡æ¯åˆ°control_result
        control_result_with_speed = control_result.copy()
        control_result_with_speed['speed_normalized'] = current_speed
        
        # ä½¿ç”¨ç»¼åˆåˆ†æå™¨åˆ†æå¸§
        if self.interp_visualizer is not None:
            analysis_results = self.interp_visualizer.analyze_frame(
                img_tensor, speed_tensor, original_image,
                control_result_with_speed, self.current_command
            )
            
            # è·å–çº¢ç»¿ç¯ä¿¡æ¯
            traffic_light_info = self._get_traffic_light_info()
            
            # è·å–æ‰€æœ‰åˆ†æ”¯é¢„æµ‹
            all_branch_predictions = self.model_predictor.get_all_branch_predictions()
            
            # æ¸²æŸ“ä»ªè¡¨æ¿
            dashboard = self.interp_visualizer.render_dashboard(
                original_image, analysis_results, control_result,
                self.current_command, traffic_light_info, all_branch_predictions
            )
            
            # åµŒå…¥å†å²æ›²çº¿å›¾åˆ° Control History é¢æ¿
            # å¸ƒå±€è®¡ç®— (2560x1440):
            # row6_y = 60 + 150 + 8 + 130 + 8 + 130 + 8 + 130 + 8 + 190 + 8 = 830
            # row6_h = (1440 - 45 - 5) - 830 = 560 (åŠ¨æ€è®¡ç®—ï¼Œæœ€å°200)
            # é¢æ¿æ ‡é¢˜é«˜åº¦çº¦25pxï¼Œæ‰€ä»¥å†…å®¹ä» row6_y + 25 å¼€å§‹
            # Historyé¢æ¿å®½åº¦ = (2560 - 24 - 20) * 0.40 â‰ˆ 1006
            if self.brake_analyzer is not None:
                # è®¡ç®—å®é™…å¯ç”¨çš„é«˜åº¦
                row6_y = 830
                footer_y = 1440 - 45
                row6_h = max(footer_y - 5 - row6_y, 200)
                
                history_w = 985  # é¢æ¿å®½åº¦å‡å»è¾¹è·
                history_h = row6_h - 30  # å‡å»æ ‡é¢˜å’Œè¾¹è·
                history_x = 18  # MARGIN + 6
                history_y = row6_y + 25  # æ ‡é¢˜é«˜åº¦
                
                history_plot = self.brake_analyzer.plot_history(width=history_w, height=history_h)
                # ç¡®ä¿ä¸è¶Šç•Œ
                y_end = min(history_y + history_h, footer_y - 5)
                x_end = min(history_x + history_w, dashboard.shape[1])
                h_actual = y_end - history_y
                w_actual = x_end - history_x
                if h_actual > 0 and w_actual > 0:
                    dashboard[history_y:y_end, history_x:x_end] = history_plot[:h_actual, :w_actual]
            
            return dashboard
        else:
            # å›é€€åˆ°ç®€å•ä»ªè¡¨æ¿
            return self._create_simple_dashboard(original_image, control_result)
    
    def _get_traffic_light_info(self):
        """è·å–æœ€è¿‘çº¢ç»¿ç¯çš„ä¿¡æ¯"""
        if self.vehicle is None or self.world is None:
            return None
        
        try:
            vehicle_location = self.vehicle.get_location()
            traffic_lights = self.world.get_actors().filter('traffic.traffic_light')
            
            nearest_tl = None
            min_distance = float('inf')
            
            for tl in traffic_lights:
                tl_location = tl.get_location()
                distance = vehicle_location.distance(tl_location)
                if distance < min_distance and distance < 50:  # 50ç±³èŒƒå›´å†…
                    min_distance = distance
                    nearest_tl = tl
            
            if nearest_tl is not None:
                state_map = {
                    carla.TrafficLightState.Red: 'Red',
                    carla.TrafficLightState.Yellow: 'Yellow',
                    carla.TrafficLightState.Green: 'Green',
                }
                state = state_map.get(nearest_tl.get_state(), 'Unknown')
                return {
                    'state': state,
                    'distance': min_distance
                }
        except:
            pass
        
        return None
    
    def _create_simple_dashboard(self, original_image, control_result):
        """åˆ›å»ºç®€å•ä»ªè¡¨æ¿ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        dash_width, dash_height = 800, 400
        dashboard = np.zeros((dash_height, dash_width, 3), dtype=np.uint8)
        dashboard[:] = (30, 30, 32)
        
        cv2.putText(dashboard, "Simple Dashboard (Interpretability module not fully loaded)", 
                    (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1, cv2.LINE_AA)
        
        # æ˜¾ç¤ºåŸå›¾
        orig_resized = cv2.resize(original_image, (300, 132))
        orig_bgr = cv2.cvtColor(orig_resized, cv2.COLOR_RGB2BGR)
        dashboard[50:182, 20:320] = orig_bgr
        
        # æ˜¾ç¤ºæ§åˆ¶å€¼
        cv2.putText(dashboard, f"Steer: {control_result['steer']:+.3f}", (350, 80),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 230, 230), 1, cv2.LINE_AA)
        cv2.putText(dashboard, f"Throttle: {control_result['throttle']:.3f}", (350, 110),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 230, 100), 1, cv2.LINE_AA)
        cv2.putText(dashboard, f"Brake: {control_result['brake']:.3f}", (350, 140),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 100, 255), 1, cv2.LINE_AA)
        
        return dashboard
    
    def _draw_panel(self, img, x, y, w, h, title, title_color=(220, 220, 220)):
        """ç»˜åˆ¶é¢æ¿ï¼ˆæ›´æ¸…æ™°çš„è¾¹æ¡†å’Œæ ‡é¢˜ï¼‰"""
        # é¢æ¿èƒŒæ™¯
        cv2.rectangle(img, (x, y), (x+w, y+h), (42, 42, 48), -1)
        # è¾¹æ¡†ï¼ˆæ›´ç²—ï¼‰
        cv2.rectangle(img, (x, y), (x+w, y+h), (70, 70, 80), 2)
        # æ ‡é¢˜ï¼ˆæ›´å¤§å­—ä½“ï¼‰
        cv2.putText(img, title, (x+8, y+18), cv2.FONT_HERSHEY_SIMPLEX, 0.55, title_color, 1, cv2.LINE_AA)
    
    def _draw_control_bar(self, img, x, y, w, h, value, label, color, warning_threshold=None):
        """ç»˜åˆ¶æ§åˆ¶æ¡ï¼ˆæ›´å¤§æ›´æ¸…æ™°ï¼‰"""
        # èƒŒæ™¯
        cv2.rectangle(img, (x, y), (x+w, y+h), (55, 55, 60), -1)
        # å€¼æ¡
        bar_w = int(w * min(1.0, max(0.0, value)))
        if warning_threshold and value > warning_threshold:
            bar_color = (60, 60, 255)  # è­¦å‘Šè‰²ï¼ˆçº¢ï¼‰
        else:
            bar_color = color
        if bar_w > 0:
            cv2.rectangle(img, (x, y), (x+bar_w, y+h), bar_color, -1)
        # è¾¹æ¡†
        cv2.rectangle(img, (x, y), (x+w, y+h), (90, 90, 100), 2)
        # æ ‡ç­¾å’Œå€¼ï¼ˆæ”¾åœ¨æ¡çš„å³ä¾§ï¼Œç•™è¶³å¤Ÿç©ºé—´ï¼‰
        text = f"{label}: {value:.3f}"
        cv2.putText(img, text, (x+w+12, y+h-6), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2, cv2.LINE_AA)
    
    def _draw_steer_bar(self, img, x, y, w, h, value, label):
        """ç»˜åˆ¶è½¬å‘æ¡ï¼ˆä¸­å¿ƒå¯¹ç§°ï¼Œæ›´æ¸…æ™°ï¼‰"""
        cv2.rectangle(img, (x, y), (x+w, y+h), (55, 55, 60), -1)
        center = x + w // 2
        steer_x = center + int((w//2) * value)
        cv2.rectangle(img, (min(center, steer_x), y), (max(center, steer_x), y+h), (0, 230, 230), -1)
        cv2.line(img, (center, y), (center, y+h), (120, 120, 130), 3)
        cv2.rectangle(img, (x, y), (x+w, y+h), (90, 90, 100), 2)
        # æ ‡ç­¾å’Œå€¼ï¼ˆæ”¾åœ¨æ¡çš„å³ä¾§ï¼Œç•™è¶³å¤Ÿç©ºé—´ï¼‰
        text = f"{label}: {value:+.3f}"
        cv2.putText(img, text, (x+w+12, y+h-6), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 230, 230), 2, cv2.LINE_AA)
    
    def _draw_stat_item(self, img, x, y, label, value, warn=False):
        """ç»˜åˆ¶ç»Ÿè®¡é¡¹ï¼ˆæ›´å¤§å­—ä½“ï¼‰"""
        color = (120, 120, 255) if warn else (220, 220, 220)
        cv2.putText(img, f"{label}:", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (170, 170, 170), 1, cv2.LINE_AA)
        cv2.putText(img, str(value), (x + 180, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1, cv2.LINE_AA)
    
    def _draw_traffic_light_indicator(self, img, x, y):
        """
        ç»˜åˆ¶çº¢ç»¿ç¯æŒ‡ç¤ºå™¨
        
        è¯´æ˜ï¼šæ˜¾ç¤º CARLA ä»¿çœŸç¯å¢ƒä¸­è½¦è¾†é™„è¿‘æœ€è¿‘çš„çº¢ç»¿ç¯çŠ¶æ€
        ç”¨é€”ï¼šå¸®åŠ©åˆ¤æ–­æ¨¡å‹åœ¨çº¢ç¯æ—¶æ˜¯å¦æ­£ç¡®è¾“å‡ºåˆ¹è½¦ä¿¡å·
        """
        if self.vehicle is None or self.world is None:
            cv2.putText(img, "N/A", (x, y+30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (100, 100, 100), 1, cv2.LINE_AA)
            return
        
        vehicle_loc = self.vehicle.get_location()
        traffic_lights = self.world.get_actors().filter('traffic.traffic_light')
        
        nearest_tl, nearest_dist = None, float('inf')
        for tl in traffic_lights:
            dist = vehicle_loc.distance(tl.get_location())
            if dist < nearest_dist:
                nearest_dist, nearest_tl = dist, tl
        
        if nearest_tl and nearest_dist < 50:
            state = str(nearest_tl.get_state()).split('.')[-1]
            
            # ç»˜åˆ¶çº¢ç»¿ç¯å›¾æ ‡ï¼ˆæ›´å¤§ï¼‰
            light_x, light_y = x + 45, y + 50
            cv2.rectangle(img, (light_x-20, light_y-45), (light_x+20, light_y+45), (25, 25, 25), -1)
            cv2.rectangle(img, (light_x-20, light_y-45), (light_x+20, light_y+45), (90, 90, 90), 2)
            
            # ä¸‰ä¸ªç¯ï¼ˆæ›´å¤§ï¼‰
            colors = [(60, 60, 60), (60, 60, 60), (60, 60, 60)]
            if 'Red' in state:
                colors[0] = (0, 0, 255)
            elif 'Yellow' in state:
                colors[1] = (0, 220, 255)
            else:
                colors[2] = (0, 255, 0)
            
            cv2.circle(img, (light_x, light_y-28), 14, colors[0], -1)
            cv2.circle(img, (light_x, light_y), 14, colors[1], -1)
            cv2.circle(img, (light_x, light_y+28), 14, colors[2], -1)
            
            # çŠ¶æ€æ–‡å­—ï¼ˆæ›´å¤§ï¼‰
            cv2.putText(img, state, (light_x + 35, light_y - 5), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (220, 220, 220), 1, cv2.LINE_AA)
            cv2.putText(img, f"Distance: {nearest_dist:.0f}m", (light_x + 35, light_y + 25), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.55, (170, 170, 170), 1, cv2.LINE_AA)
            
            # çº¢ç¯è­¦å‘Šï¼ˆæ›´é†’ç›®ï¼‰
            if 'Red' in state and nearest_dist < 30:
                all_preds = self.model_predictor.get_all_branch_predictions()
                if all_preds is not None:
                    max_brake = max(all_preds[2], all_preds[5], all_preds[8], all_preds[11])
                    if max_brake < 0.3:
                        cv2.rectangle(img, (x, y + 95), (x + 200, y + 120), (0, 0, 180), -1)
                        cv2.putText(img, "WARNING: LOW BRAKE!", (x + 10, y + 113), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1, cv2.LINE_AA)
        else:
            cv2.putText(img, "No traffic light", (x, y + 40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (120, 120, 120), 1, cv2.LINE_AA)
            cv2.putText(img, "within 50m", (x, y + 65), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.55, (100, 100, 100), 1, cv2.LINE_AA)
    
    def _save_interpretability_frame(self, original_image, control_result):
        """ä¿å­˜å¯è§£é‡Šæ€§å¸§"""
        if self.interpret_save_dir is None:
            self.interpret_save_dir = './interpret_output'
        
        import os
        os.makedirs(self.interpret_save_dir, exist_ok=True)
        
        filename = f"interp_{self.frame_count:06d}.png"
        filepath = os.path.join(self.interpret_save_dir, filename)
        
        # ä¿å­˜åŸå›¾
        orig_bgr = cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR)
        cv2.imwrite(filepath, orig_bgr)
        
        print(f"âœ… å·²ä¿å­˜: {filepath}")
    
    def _print_brake_statistics(self):
        """æ‰“å°åˆ¹è½¦ç»Ÿè®¡å’Œå¯è§£é‡Šæ€§æŒ‡æ ‡"""
        if self.brake_analyzer is None:
            print("åˆ¹è½¦åˆ†æå™¨æœªåˆå§‹åŒ–")
            return
        
        stats = self.brake_analyzer.get_statistics()
        print(f"\n{'='*60}")
        print("åˆ¹è½¦è¡Œä¸ºç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"æ€»å¸§æ•°: {stats.get('total_frames', 0)}")
        print(f"åˆ¹è½¦å¸§å æ¯” (>0.1): {stats.get('brake_ratio', 0)*100:.1f}%")
        print(f"æ€¥åˆ¹è½¦å¸§å æ¯” (>0.5): {stats.get('hard_brake_ratio', 0)*100:.1f}%")
        print(f"å¹³å‡åˆ¹è½¦å€¼: {stats.get('avg_brake', 0):.3f}")
        print(f"æœ€å¤§åˆ¹è½¦å€¼: {stats.get('max_brake', 0):.3f}")
        
        # æ‰“å°å¯è§£é‡Šæ€§å®šé‡æŒ‡æ ‡
        if self.interp_visualizer is not None:
            print(f"\n{'='*60}")
            print("å¯è§£é‡Šæ€§å®šé‡æŒ‡æ ‡æ±‡æ€» (Academic Metrics)")
            print(f"{'='*60}")
            summary = self.interp_visualizer.get_metrics_summary()
            
            if summary:
                occ = summary.get('occlusion_sensitivity', {})
                ig = summary.get('integrated_gradients', {})
                di = summary.get('deletion_insertion', {})
                
                print(f"åˆ†æå¸§æ•°: {summary.get('total_frames_analyzed', 0)}")
                print(f"\né®æŒ¡æ•æ„Ÿæ€§ (Occlusion Sensitivity):")
                print(f"  å¹³å‡å€¼: {occ.get('mean', 0):.4f}")
                print(f"  æ ‡å‡†å·®: {occ.get('std', 0):.4f}")
                
                print(f"\nç§¯åˆ†æ¢¯åº¦ (Integrated Gradients):")
                print(f"  å®Œæ•´æ€§è¯¯å·®: {ig.get('mean_completeness_error', 0):.4f}")
                
                print(f"\nåˆ é™¤/æ’å…¥æ›²çº¿ (Deletion/Insertion):")
                print(f"  åˆ é™¤AUC (è¶Šä½è¶Šå¥½): {di.get('mean_deletion_auc', 0):.4f}")
                print(f"  æ’å…¥AUC (è¶Šé«˜è¶Šå¥½): {di.get('mean_insertion_auc', 0):.4f}")
                print(f"  ç»¼åˆå¾—åˆ†: {di.get('mean_combined_score', 0):+.4f}")
            
            # å¯¼å‡ºæŒ‡æ ‡åˆ°æ–‡ä»¶
            if self.interpret_save_dir:
                metrics_path = os.path.join(self.interpret_save_dir, 'metrics.json')
                self.interp_visualizer.save_metrics(metrics_path)
                print(f"\nğŸ“Š æŒ‡æ ‡å·²å¯¼å‡ºåˆ°: {metrics_path}")
        
        print(f"{'='*60}\n")

    def _debug_print_all_branches(self, control_result):
        """è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰åˆ†æ”¯çš„é¢„æµ‹å€¼"""
        all_predictions = self.model_predictor.get_all_branch_predictions()
        if all_predictions is None:
            return
            
        print(f"\n{'='*70}")
        print(f"[è°ƒè¯•] æ‰€æœ‰åˆ†æ”¯é¢„æµ‹å€¼ (å¸§ {self.frame_count})")
        print(f"{'='*70}")
        print(f"å½“å‰å‘½ä»¤: {self.current_command} ({COMMAND_NAMES_EN.get(self.current_command, 'Unknown')})")
        print(f"å½“å‰åˆ†æ”¯ç´¢å¼•: {self.current_command - 2}")
        print(f"\n{'åˆ†æ”¯':<12} {'å‘½ä»¤':<10} {'Steer':<10} {'Throttle':<10} {'Brake':<10} {'ä½¿ç”¨?'}")
        print(f"{'-'*70}")
        
        branch_names = ['Follow', 'Left', 'Right', 'Straight']
        for i, name in enumerate(branch_names):
            start_idx = i * 3
            steer = all_predictions[start_idx]
            throttle = all_predictions[start_idx + 1]
            brake = all_predictions[start_idx + 2]
            
            is_current = '>>> YES' if (i == self.current_command - 2) else ''
            
            print(f"Branch {i:<4} {name:<10} {steer:+.3f}     {throttle:.3f}      {brake:.3f}      {is_current}")
        
        print(f"{'='*70}")
        print(f"{'='*70}\n")
    
    def _print_status(self, start_time, current_speed, control_result):
        """æ‰“å°çŠ¶æ€ä¿¡æ¯"""
        elapsed = time.time() - start_time
        fps = self.frame_count / elapsed
        
        actual_speed = current_speed * SPEED_NORMALIZATION_MPS * 3.6
        route_info = self.navigation_planner.get_route_info(self.vehicle)
        command_en = COMMAND_NAMES_EN.get(route_info['current_command'], 'Unknown')
        
        print(f"[{elapsed:.1f}s] "
              f"Cmd: {command_en:8s} | "
              f"Prog: {route_info['progress']:5.1f}% | "
              f"Dist: {route_info['remaining_distance']:4.0f}m | "
              f"Spd: {actual_speed:4.1f} | "
              f"Str: {control_result['steer']:+.3f} | "
              f"Thr: {control_result['throttle']:.3f} | "
              f"Brk: {control_result['brake']:.3f} | "
              f"FPS: {fps:.1f}")
              
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if self.frame_count == 0:
            return
            
        print(f"\n{'='*60}")
        print("æ¨ç†ç»Ÿè®¡ä¿¡æ¯")
        print(f"{'='*60}")
        print(f"æ€»å¸§æ•°: {self.frame_count}")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {self.total_inference_time/self.frame_count*1000:.2f} ms")
        print(f"{'='*60}\n")
        
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("æ­£åœ¨æ¸…ç†èµ„æº...")
        
        # æ¸…ç†å¯è§£é‡Šæ€§æ¨¡å—ï¼ˆé‡Šæ”¾é’©å­å’Œå†…å­˜ï¼‰
        if self.interp_visualizer is not None:
            self.interp_visualizer.cleanup()
            print("  - å¯è§£é‡Šæ€§æ¨¡å—å·²æ¸…ç†")
        
        if self.sensor_manager is not None:
            self.sensor_manager.cleanup()
            
        if self.vehicle is not None:
            self.vehicle.destroy()
        
        # æ¸…ç†NPC
        if self.npc_manager is not None:
            self.npc_manager.cleanup_all()
            
        if self.world is not None:
            settings = self.world.get_settings()
            settings.synchronous_mode = False
            self.world.apply_settings(settings)
            
        print("æ¸…ç†å®Œæˆï¼")


def str2bool(v):
    """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¸ƒå°”å€¼"""
    if isinstance(v, bool):
        return v
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Carlaè‡ªåŠ¨é©¾é©¶æ¨¡å‹å®æ—¶æ¨ç†ï¼ˆæ¨¡å—åŒ–ç‰ˆæœ¬ï¼‰')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model-path', type=str, default='./model/ddp_dynamic_5_best.pth',
                        help='è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--net-structure', type=int, default=2,
                        help='ç½‘ç»œç»“æ„ç±»å‹ (1|2|3)')
    parser.add_argument('--gpu', type=int, default=0,
                        help='GPU IDï¼Œ-1è¡¨ç¤ºä½¿ç”¨CPU')
    
    # Carlaå‚æ•°
    parser.add_argument('--host', type=str, default='localhost',
                        help='CarlaæœåŠ¡å™¨åœ°å€')
    parser.add_argument('--port', type=int, default=2000,
                        help='CarlaæœåŠ¡å™¨ç«¯å£')
    parser.add_argument('--town', type=str, default='Town01',
                        help='åœ°å›¾åç§°')
    parser.add_argument('--vehicle', type=str, default='vehicle.tesla.model3',
                        help='è½¦è¾†ç±»å‹')
    
    # è·¯çº¿è§„åˆ’å‚æ•°
    parser.add_argument('--spawn-index', type=int, default=1,
                        help='èµ·ç‚¹ç´¢å¼•')
    parser.add_argument('--dest-index', type=int, default=41,
                        help='ç»ˆç‚¹ç´¢å¼•')
    parser.add_argument('--list-spawns', action='store_true',        
                        help='åˆ—å‡ºæ‰€æœ‰ç”Ÿæˆç‚¹ä½ç½®åé€€å‡º')
    
    # è¿è¡Œå‚æ•°
    parser.add_argument('--duration', type=int, default=-1,
                        help='è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ-1è¡¨ç¤ºæ— é™è¿è¡Œ')
    
    # åŠŸèƒ½å¼€å…³
    parser.add_argument('--auto-replan', type=str2bool, default=True,
                        help='åˆ°è¾¾ç›®çš„åœ°åè‡ªåŠ¨é‡æ–°è§„åˆ’è·¯çº¿')
    parser.add_argument('--visualize', type=str2bool, default=True,
                        help='æ˜¾ç¤ºå¯è§†åŒ–çª—å£')
    parser.add_argument('--post-processing', type=str2bool, default=True,
                        help='å¯ç”¨æ¨¡å‹è¾“å‡ºåå¤„ç†ï¼ˆå¯å‘å¼è§„åˆ™ä¼˜åŒ–ï¼‰')
    parser.add_argument('--image-crop', type=str2bool, default=True,
                        help='å¯ç”¨å›¾åƒè£å‰ªï¼ˆå»é™¤å¤©ç©ºå’Œå¼•æ“ç›–ï¼Œä¸è®­ç»ƒä¸€è‡´ï¼‰')
    parser.add_argument('--vis-mode', type=str, default='spectator',
                        choices=['spectator', 'opencv'],
                        help='å¯è§†åŒ–æ¨¡å¼: spectator=CARLAçª—å£ç¬¬ä¸‰äººç§°è·Ÿéš(æ¨è), opencv=ç‹¬ç«‹å°çª—å£(æ—§æ¨¡å¼)')
    
    # å¤©æ°”å‚æ•°
    parser.add_argument('--weather', type=str, default='ClearSunset',
                        help='å¤©æ°”é¢„è®¾: ClearNoon, ClearSunset, CloudyNoon, CloudySunset, '
                             'WetNoon, WetSunset, WetCloudyNoon, WetCloudySunset, '
                             'HardRainNoon, HardRainSunset, SoftRainNoon, SoftRainSunset')
    
    # NPCå‚æ•°
    parser.add_argument('--npc-vehicles', type=int, default=0,
                        help='NPCè½¦è¾†æ•°é‡ï¼Œ0è¡¨ç¤ºä¸ç”Ÿæˆ')
    parser.add_argument('--npc-walkers', type=int, default=0,
                        help='NPCè¡Œäººæ•°é‡ï¼Œ0è¡¨ç¤ºä¸ç”Ÿæˆ')
    parser.add_argument('--npc-ignore-lights', type=str2bool, default=False,
                        help='NPCè½¦è¾†æ˜¯å¦å¿½ç•¥çº¢ç»¿ç¯ï¼ˆé»˜è®¤éµå®ˆï¼‰')
    parser.add_argument('--npc-ignore-signs', type=str2bool, default=True,
                        help='NPCè½¦è¾†æ˜¯å¦å¿½ç•¥äº¤é€šæ ‡å¿—ï¼ˆé»˜è®¤éµå®ˆï¼‰')
    parser.add_argument('--npc-vehicle-distance', type=float, default=5.0,
                        help='NPCè½¦è¾†è·Ÿè½¦è·ç¦»ï¼ˆç±³ï¼‰')
    parser.add_argument('--npc-speed-diff', type=float, default=30.0,
                        help='NPCè½¦è¾†é€Ÿåº¦å·®å¼‚ç™¾åˆ†æ¯”')
    
    # å¯è§£é‡Šæ€§å‚æ•°
    parser.add_argument('--interpret', type=str2bool, default=False,
                        help='å¯ç”¨å¯è§£é‡Šæ€§å¯è§†åŒ–ï¼ˆGrad-CAMçƒ­åŠ›å›¾ã€åˆ¹è½¦åˆ†æç­‰ï¼‰')
    parser.add_argument('--interpret-save-dir', type=str, default='./interpret_output_1_best',
                        help='å¯è§£é‡Šæ€§åˆ†æç»“æœä¿å­˜ç›®å½•')
    parser.add_argument('--interpret-save-interval', type=int, default=1,
                        help='å¯è§£é‡Šæ€§ä»ªè¡¨æ¿ä¿å­˜é¢‘ç‡ï¼ˆæ¯Nå¸§ä¿å­˜ä¸€æ¬¡ï¼Œ0è¡¨ç¤ºä¸è‡ªåŠ¨ä¿å­˜ï¼‰')
    parser.add_argument('--interpret-device', type=str, default='gpu',
                        choices=['gpu', 'cpu'],
                        help='å¯è§£é‡Šæ€§åˆ†æè®¡ç®—è®¾å¤‡: gpu=ä½¿ç”¨GPU(å¿«ä½†ä¸CARLAç«äº‰èµ„æº), cpu=ä½¿ç”¨CPU(æ…¢ä½†ä¸å½±å“CARLAæ¸²æŸ“)')
    parser.add_argument('--interpret-full', type=str2bool, default=False,
                        help='å¯ç”¨å®Œæ•´å¯è§£é‡Šæ€§åˆ†æ(Occlusion/IG/Deletion-Insertion)ï¼ŒFalseåˆ™åªç”¨Grad-CAM')
    parser.add_argument('--interpret-row1-layer', type=int, default=-3,
                        help='ç¬¬ä¸€è¡Œçƒ­åŠ›å›¾ä½¿ç”¨çš„å·ç§¯å±‚ç´¢å¼• (-1=æœ€åå±‚, -3=æ¨è, -5=é«˜åˆ†è¾¨ç‡)')
    parser.add_argument('--interpret-row2-layers', type=str, default='-8,-7,-6,-5,-4,-3,-2,-1',
                        help='ç¬¬äºŒè¡Œå¤šå±‚çº§çƒ­åŠ›å›¾ä½¿ç”¨çš„å·ç§¯å±‚ç´¢å¼•åˆ—è¡¨ï¼Œé€—å·åˆ†éš” (å¦‚: -8,-7,-6,-5,-4,-3,-2,-1 è¡¨ç¤ºæ‰€æœ‰8å±‚)')
    parser.add_argument('--interpret-ig-steps', type=int, default=30,
                        help='ç§¯åˆ†æ¢¯åº¦(Integrated Gradients)çš„ç§¯åˆ†æ­¥æ•°ï¼Œè¶Šå¤§ç²¾åº¦è¶Šé«˜ä½†è¶Šæ…¢ (æ¨è: 30-50)')
    
    args = parser.parse_args()
    
    # å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºåŸºäºè„šæœ¬ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    if not os.path.isabs(args.model_path):
        args.model_path = os.path.join(script_dir, args.model_path)
    
    # åˆ›å»ºNPCé…ç½®ï¼ˆå¦‚æœéœ€è¦ï¼‰
    npc_config = None
    if args.npc_vehicles > 0 or args.npc_walkers > 0:
        npc_config = NPCConfig(
            num_vehicles=args.npc_vehicles,
            num_walkers=args.npc_walkers,
            vehicles_ignore_lights=args.npc_ignore_lights,
            vehicles_ignore_signs=args.npc_ignore_signs,
            vehicle_distance=args.npc_vehicle_distance,
            vehicle_speed_difference=args.npc_speed_diff
        )
    
    # è§£æç¬¬äºŒè¡Œå¤šå±‚çº§çƒ­åŠ›å›¾çš„å±‚ç´¢å¼•
    interpret_row2_layers = [int(x.strip()) for x in args.interpret_row2_layers.split(',')]
    
    # åˆ›å»ºæ¨ç†å™¨
    inferencer = CarlaInference(
        model_path=args.model_path,
        host=args.host,
        port=args.port,
        town=args.town,
        gpu_id=args.gpu,
        enable_post_processing=args.post_processing,
        enable_image_crop=args.image_crop,
        visualization_mode=args.vis_mode,
        npc_config=npc_config,
        weather=args.weather,
        enable_interpretability=args.interpret,
        interpret_save_dir=args.interpret_save_dir,
        interpret_save_interval=args.interpret_save_interval,
        interpret_device=args.interpret_device,
        interpret_full_analysis=args.interpret_full,
        interpret_row1_layer=args.interpret_row1_layer,
        interpret_row2_layers=interpret_row2_layers,
        interpret_ig_steps=args.interpret_ig_steps
    )
    
    try:
        # åˆå§‹åŒ–
        inferencer.load_model(net_structure=args.net_structure)
        inferencer.connect_carla()
        
        # å¦‚æœæ˜¯åˆ—å‡ºç”Ÿæˆç‚¹æ¨¡å¼
        if args.list_spawns:
            spawn_points = inferencer.world.get_map().get_spawn_points()
            print(f"\n{'='*80}")
            print(f"{args.town} åœ°å›¾çš„æ‰€æœ‰ç”Ÿæˆç‚¹ï¼ˆå…± {len(spawn_points)} ä¸ªï¼‰")
            print(f"{'='*80}")
            print(f"{'ç´¢å¼•':<6} {'Xåæ ‡':<12} {'Yåæ ‡':<12} {'Zåæ ‡':<12} {'æœå‘(Yaw)':<12}")
            print(f"{'-'*80}")
            
            for i, spawn in enumerate(spawn_points):
                loc = spawn.location
                rot = spawn.rotation
                print(f"{i:<6} {loc.x:<12.2f} {loc.y:<12.2f} {loc.z:<12.2f} {rot.yaw:<12.2f}")
            
            print(f"{'='*80}")
            return
        
        inferencer.spawn_vehicle(
            vehicle_filter=args.vehicle,
            spawn_index=args.spawn_index,
            destination_index=args.dest_index
        )
        inferencer.setup_sensors()
        
        # ç­‰å¾…ä¼ æ„Ÿå™¨åˆå§‹åŒ–
        time.sleep(1.0)
        
        # è¿è¡Œæ¨ç†
        inferencer.run_inference(
            duration=args.duration,
            visualize=args.visualize,
            auto_replan=args.auto_replan
        )
        
        # æ‰“å°ç»Ÿè®¡
        inferencer.print_statistics()
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
        
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        inferencer.cleanup()
        print("ç¨‹åºç»“æŸ")


if __name__ == '__main__':
    main()
