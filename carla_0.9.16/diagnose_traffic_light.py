#!/usr/bin/env python
# coding=utf-8
'''
çº¢ç»¿ç¯åœºæ™¯è¯Šæ–­è„šæœ¬
ä¸“é—¨ç”¨äºåˆ†ææ¨¡å‹åœ¨çº¢ç»¿ç¯åœºæ™¯çš„è¡Œä¸º

ä½¿ç”¨æ–¹æ³•:
    python diagnose_traffic_light.py --model-path ./model/your_model.pth

åŠŸèƒ½:
1. å®æ—¶ Grad-CAM å¯è§†åŒ– - æŸ¥çœ‹æ¨¡å‹å…³æ³¨çš„åŒºåŸŸ
2. åˆ¹è½¦é¢„æµ‹åˆ†æ - ç»Ÿè®¡åˆ¹è½¦è¡Œä¸º
3. åˆ†æ”¯è¾“å‡ºå¯¹æ¯” - åˆ†ææ‰€æœ‰åˆ†æ”¯çš„å·®å¼‚
4. ä¿å­˜è¯Šæ–­å¸§ - ç”¨äºç¦»çº¿åˆ†æ
'''

import os
import sys
import time
import argparse
import cv2
import numpy as np
import torch

# è®¾ç½®ç¼–ç 
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import carla

from carla_config import *
from carla_sensors import SensorManager
from carla_model_loader import ModelLoader
from carla_image_processor import ImageProcessor
from carla_vehicle_controller import VehicleController
from carla_vehicle_spawner import VehicleSpawner
from navigation_planner_adapter import NavigationPlannerAdapter
from carla_interpretability import InterpretabilityVisualizer, GradCAM, BrakeAnalyzer


class TrafficLightDiagnoser:
    """çº¢ç»¿ç¯åœºæ™¯è¯Šæ–­å™¨"""
    
    def __init__(self, model_path, host='localhost', port=2000, town='Town01', 
                 gpu_id=0, save_dir='./diagnose_output'):
        self.host = host
        self.port = port
        self.town = town
        self.save_dir = save_dir
        
        # è®¾å¤‡
        self.device = torch.device(
            f'cuda:{gpu_id}' if gpu_id >= 0 and torch.cuda.is_available() else 'cpu'
        )
        
        # æ¨¡å—
        self.model_loader = ModelLoader(model_path, self.device)
        self.image_processor = ImageProcessor(self.device, enable_crop=True)
        self.vehicle_controller = VehicleController()
        
        # CARLA å¯¹è±¡
        self.client = None
        self.world = None
        self.vehicle = None
        self.sensor_manager = None
        self.navigation_planner = None
        self.vehicle_spawner = None
        
        # æ¨¡å‹
        self.model = None
        
        # å¯è§£é‡Šæ€§å·¥å…·
        self.interp_viz = None
        self.grad_cam = None
        self.brake_analyzer = BrakeAnalyzer(history_size=200)
        
        # çŠ¶æ€
        self.frame_count = 0
        self.all_branch_predictions = None
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        print(f"è¯Šæ–­å™¨åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
        print(f"è¯Šæ–­ç»“æœå°†ä¿å­˜åˆ°: {save_dir}")
    
    def load_model(self, net_structure=2):
        """åŠ è½½æ¨¡å‹"""
        self.model = self.model_loader.load()
        self.model.eval()
        
        # åˆå§‹åŒ–å¯è§£é‡Šæ€§å·¥å…·
        self.grad_cam = GradCAM(self.model)
        self.interp_viz = InterpretabilityVisualizer(
            self.model, self.device, self.save_dir
        )
        
        print("âœ… æ¨¡å‹å’Œå¯è§£é‡Šæ€§å·¥å…·åŠ è½½å®Œæˆ")
    
    def connect_carla(self):
        """è¿æ¥ CARLA"""
        print(f"æ­£åœ¨è¿æ¥åˆ° CARLA æœåŠ¡å™¨ {self.host}:{self.port}...")
        
        self.client = carla.Client(self.host, self.port)
        self.client.set_timeout(10.0)
        
        print(f"æ­£åœ¨åŠ è½½åœ°å›¾ {self.town}...")
        self.world = self.client.load_world(self.town)
        
        # åŒæ­¥æ¨¡å¼
        settings = self.world.get_settings()
        settings.synchronous_mode = True
        settings.fixed_delta_seconds = SYNC_MODE_DELTA_SECONDS
        self.world.apply_settings(settings)
        
        self.vehicle_spawner = VehicleSpawner(self.world)
        self.navigation_planner = NavigationPlannerAdapter(
            self.world, sampling_resolution=ROUTE_SAMPLING_RESOLUTION
        )
        
        print("âœ… CARLA è¿æ¥æˆåŠŸ")
    
    def spawn_vehicle(self, spawn_index=None, dest_index=None):
        """ç”Ÿæˆè½¦è¾†"""
        self.vehicle = self.vehicle_spawner.spawn('vehicle.tesla.model3', spawn_index)
        self.sensor_manager = SensorManager(self.world, self.vehicle)
        
        for _ in range(3):
            self.world.tick()
        
        # è®¾ç½®ç›®çš„åœ°
        spawn_points = self.world.get_map().get_spawn_points()
        if dest_index is not None and 0 <= dest_index < len(spawn_points):
            destination = spawn_points[dest_index].location
            self.navigation_planner.set_destination(self.vehicle, destination)
        else:
            self.navigation_planner.set_random_destination(self.vehicle)
        
        self.sensor_manager.setup_camera()
        print("âœ… è½¦è¾†ç”Ÿæˆå®Œæˆ")
    
    def predict(self, img_tensor, speed_tensor, current_command):
        """æ¨¡å‹é¢„æµ‹ï¼ˆä¿å­˜æ‰€æœ‰åˆ†æ”¯è¾“å‡ºï¼‰"""
        with torch.no_grad():
            pred_control, pred_speed, log_var_control, log_var_speed = \
                self.model(img_tensor, speed_tensor)
        
        pred_control = pred_control.cpu().numpy()[0]
        self.all_branch_predictions = pred_control.copy()
        
        branch_idx = current_command - 2
        start_idx = branch_idx * 3
        
        steer = float(pred_control[start_idx])
        throttle = float(pred_control[start_idx + 1])
        brake = float(pred_control[start_idx + 2])
        
        # Clip
        steer = np.clip(steer, -1.0, 1.0)
        throttle = np.clip(throttle, 0.0, 1.0)
        brake = np.clip(brake, 0.0, 1.0)
        
        return {
            'steer': steer,
            'throttle': throttle,
            'brake': brake,
            'pred_speed': pred_speed.cpu().numpy()[0][0] * MAX_SPEED_KMH,
            'pred_speed_normalized': pred_speed.cpu().numpy()[0][0],
        }
    
    def run_diagnosis(self, duration=120, save_interval=10):
        """
        è¿è¡Œè¯Šæ–­
        
        å‚æ•°:
            duration: è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
            save_interval: ä¿å­˜é—´éš”ï¼ˆå¸§ï¼‰
        """
        print(f"\n{'='*70}")
        print("å¼€å§‹çº¢ç»¿ç¯åœºæ™¯è¯Šæ–­")
        print(f"{'='*70}")
        print(f"è¿è¡Œæ—¶é•¿: {duration}ç§’")
        print(f"ä¿å­˜é—´éš”: æ¯{save_interval}å¸§")
        print("æŒ‰ 'q' é€€å‡º, 's' æ‰‹åŠ¨ä¿å­˜å½“å‰å¸§, 'p' æ‰“å°ç»Ÿè®¡")
        print(f"{'='*70}\n")
        
        # ç­‰å¾…æ‘„åƒå¤´
        print("ç­‰å¾…æ‘„åƒå¤´æ•°æ®...")
        while not self.sensor_manager.has_image():
            self.world.tick()
            time.sleep(0.01)
        print("æ‘„åƒå¤´å°±ç»ªï¼\n")
        
        start_time = time.time()
        self.frame_count = 0
        
        # åˆ›å»ºçª—å£
        cv2.namedWindow('Traffic Light Diagnosis', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Traffic Light Diagnosis', 1200, 700)
        
        try:
            while True:
                # æ£€æŸ¥è¶…æ—¶
                if duration > 0 and time.time() - start_time > duration:
                    print(f"\nå·²è¿è¡Œ {duration} ç§’ï¼Œåœæ­¢è¯Šæ–­")
                    break
                
                self.world.tick()
                
                if not self.sensor_manager.has_image():
                    continue
                
                # æ›´æ–°å¯¼èˆª
                self.navigation_planner.run_step()
                current_command = self.navigation_planner.get_navigation_command(self.vehicle)
                
                # è·å–æ•°æ®
                current_image = self.sensor_manager.get_latest_image()
                current_speed = self.vehicle_controller.get_speed_normalized(
                    self.vehicle, SPEED_NORMALIZATION_MPS
                )
                
                # é¢„å¤„ç†
                img_tensor = self.image_processor.preprocess(current_image)
                speed_tensor = torch.FloatTensor([[current_speed]]).to(self.device)
                
                # é¢„æµ‹
                control_result = self.predict(img_tensor, speed_tensor, current_command)
                control_result['speed_normalized'] = current_speed
                
                # è·å–å¤„ç†åçš„å›¾åƒï¼ˆæ¨¡å‹è¾“å…¥ï¼‰
                model_input_image = self.image_processor.get_processed_image(current_image)
                
                # å¯è§£é‡Šæ€§åˆ†æ
                analysis_results = self.interp_viz.analyze_frame(
                    img_tensor, speed_tensor, model_input_image,
                    control_result, current_command
                )
                
                # åˆ›å»ºä»ªè¡¨æ¿ï¼ˆä½¿ç”¨render_dashboardæ–¹æ³•ï¼‰
                dashboard = self.interp_viz.render_dashboard(
                    model_input_image, analysis_results, 
                    control_result, current_command
                )
                
                # æ·»åŠ åˆ†æ”¯å¯¹æ¯”
                dashboard = self._add_branch_comparison(dashboard, current_command)
                
                # æ·»åŠ çº¢ç»¿ç¯æ£€æµ‹çŠ¶æ€
                dashboard = self._add_traffic_light_status(dashboard)
                
                # æ˜¾ç¤º
                cv2.imshow('Traffic Light Diagnosis', dashboard)
                
                # åº”ç”¨æ§åˆ¶ï¼ˆå¯é€‰ï¼šä¸åº”ç”¨æ§åˆ¶ï¼Œåªè§‚å¯Ÿï¼‰
                self.vehicle_controller.apply_control(
                    self.vehicle,
                    control_result['steer'],
                    control_result['throttle'],
                    control_result['brake']
                )
                
                self.frame_count += 1
                
                # å®šæœŸä¿å­˜
                if self.frame_count % save_interval == 0:
                    self._save_diagnosis_frame(dashboard, model_input_image, 
                                               analysis_results, control_result)
                
                # æ‰“å°çŠ¶æ€
                if self.frame_count % 20 == 0:
                    self._print_status(current_speed, control_result, current_command)
                
                # é”®ç›˜å¤„ç†
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("\nç”¨æˆ·é€€å‡º")
                    break
                elif key == ord('s'):
                    self._save_diagnosis_frame(dashboard, model_input_image,
                                               analysis_results, control_result, manual=True)
                elif key == ord('p'):
                    self._print_statistics()
                
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­")
        
        finally:
            cv2.destroyAllWindows()
            self._print_final_report()
    
    def _add_branch_comparison(self, dashboard, current_command):
        """æ·»åŠ åˆ†æ”¯å¯¹æ¯”åˆ°ä»ªè¡¨æ¿"""
        if self.all_branch_predictions is None:
            return dashboard
        
        x_start = 450
        y_start = 400
        
        cv2.putText(dashboard, "All Branches Comparison:", (x_start, y_start),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)
        
        branch_names = ['Follow', 'Left', 'Right', 'Straight']
        
        for i, name in enumerate(branch_names):
            y = y_start + 20 + i * 20
            start_idx = i * 3
            
            steer = self.all_branch_predictions[start_idx]
            throttle = self.all_branch_predictions[start_idx + 1]
            brake = self.all_branch_predictions[start_idx + 2]
            
            # é«˜äº®å½“å‰åˆ†æ”¯
            color = (0, 255, 255) if i == current_command - 2 else (150, 150, 150)
            marker = ">>>" if i == current_command - 2 else "   "
            
            text = f"{marker} {name:8s}: S={steer:+.2f} T={throttle:.2f} B={brake:.2f}"
            cv2.putText(dashboard, text, (x_start, y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.35, color, 1)
        
        return dashboard
    
    def _add_traffic_light_status(self, dashboard):
        """æ·»åŠ çº¢ç»¿ç¯æ£€æµ‹çŠ¶æ€"""
        # æ£€æµ‹é™„è¿‘çš„çº¢ç»¿ç¯
        if self.vehicle is None:
            return dashboard
        
        vehicle_loc = self.vehicle.get_location()
        traffic_lights = self.world.get_actors().filter('traffic.traffic_light')
        
        nearest_tl = None
        nearest_dist = float('inf')
        
        for tl in traffic_lights:
            dist = vehicle_loc.distance(tl.get_location())
            if dist < nearest_dist:
                nearest_dist = dist
                nearest_tl = tl
        
        # æ˜¾ç¤ºçº¢ç»¿ç¯çŠ¶æ€
        x, y = 640, 200
        cv2.putText(dashboard, "Traffic Light:", (x, y),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)
        
        if nearest_tl and nearest_dist < 50:
            state = nearest_tl.get_state()
            state_name = str(state).split('.')[-1]
            
            # é¢œè‰²
            if 'Red' in state_name:
                color = (0, 0, 255)
            elif 'Yellow' in state_name:
                color = (0, 255, 255)
            else:
                color = (0, 255, 0)
            
            cv2.putText(dashboard, f"{state_name} ({nearest_dist:.1f}m)", (x, y + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            # å¦‚æœæ˜¯çº¢ç¯ä½†æ²¡åˆ¹è½¦ï¼Œè­¦å‘Š
            if 'Red' in state_name and nearest_dist < 30:
                if self.all_branch_predictions is not None:
                    # æ£€æŸ¥æ‰€æœ‰åˆ†æ”¯çš„åˆ¹è½¦å€¼
                    max_brake = max(self.all_branch_predictions[2], 
                                    self.all_branch_predictions[5],
                                    self.all_branch_predictions[8],
                                    self.all_branch_predictions[11])
                    if max_brake < 0.3:
                        cv2.putText(dashboard, "WARNING: Red light but low brake!", 
                                    (x, y + 45), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
        else:
            cv2.putText(dashboard, "None nearby", (x, y + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 100, 100), 1)
        
        return dashboard
    
    def _save_diagnosis_frame(self, dashboard, model_input, results, control, manual=False):
        """ä¿å­˜è¯Šæ–­å¸§"""
        prefix = "manual" if manual else "auto"
        timestamp = time.strftime("%H%M%S")
        
        # ä¿å­˜ä»ªè¡¨æ¿
        filename = f"{prefix}_{self.frame_count:06d}_{timestamp}.png"
        filepath = os.path.join(self.save_dir, filename)
        cv2.imwrite(filepath, dashboard)
        
        # ä¿å­˜ Grad-CAMï¼ˆä½¿ç”¨brake_camé”®ï¼Œå¹¶ç”Ÿæˆå åŠ å›¾åƒï¼‰
        brake_cam = results.get('brake_cam')
        if brake_cam is not None:
            # ç”Ÿæˆçƒ­åŠ›å›¾å åŠ å›¾åƒ
            heatmap = cv2.applyColorMap(np.uint8(255 * brake_cam), cv2.COLORMAP_JET)
            # å°†model_inputè½¬æ¢ä¸ºBGRæ ¼å¼
            if len(model_input.shape) == 3 and model_input.shape[2] == 3:
                model_input_bgr = cv2.cvtColor(model_input, cv2.COLOR_RGB2BGR)
            else:
                model_input_bgr = model_input
            # è°ƒæ•´çƒ­åŠ›å›¾å°ºå¯¸ä»¥åŒ¹é…è¾“å…¥å›¾åƒ
            heatmap_resized = cv2.resize(heatmap, (model_input_bgr.shape[1], model_input_bgr.shape[0]))
            # å åŠ 
            cam_overlay = cv2.addWeighted(model_input_bgr, 0.4, heatmap_resized, 0.6, 0)
            
            cam_filename = f"gradcam_{self.frame_count:06d}.png"
            cam_filepath = os.path.join(self.save_dir, cam_filename)
            cv2.imwrite(cam_filepath, cam_overlay)
        
        if manual:
            print(f"âœ… æ‰‹åŠ¨ä¿å­˜: {filepath}")
    
    def _print_status(self, speed, control, command):
        """æ‰“å°çŠ¶æ€"""
        cmd_names = {2: 'Follow', 3: 'Left', 4: 'Right', 5: 'Straight'}
        actual_speed = speed * SPEED_NORMALIZATION_MPS
        
        print(f"[Frame {self.frame_count:5d}] "
              f"Cmd: {cmd_names.get(command, '?'):8s} | "
              f"Spd: {actual_speed:5.1f} km/h | "
              f"Str: {control['steer']:+.3f} | "
              f"Thr: {control['throttle']:.3f} | "
              f"Brk: {control['brake']:.3f}")
    
    def _print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.brake_analyzer.get_statistics()
        
        print(f"\n{'='*50}")
        print("åˆ¹è½¦è¡Œä¸ºç»Ÿè®¡")
        print(f"{'='*50}")
        print(f"æ€»å¸§æ•°: {stats.get('total_frames', 0)}")
        print(f"åˆ¹è½¦å¸§å æ¯” (>0.1): {stats.get('brake_ratio', 0)*100:.1f}%")
        print(f"æ€¥åˆ¹è½¦å¸§å æ¯” (>0.5): {stats.get('hard_brake_ratio', 0)*100:.1f}%")
        print(f"å¹³å‡åˆ¹è½¦å€¼: {stats.get('avg_brake', 0):.3f}")
        print(f"æœ€å¤§åˆ¹è½¦å€¼: {stats.get('max_brake', 0):.3f}")
        print(f"{'='*50}\n")
    
    def _print_final_report(self):
        """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""
        print(f"\n{'='*70}")
        print("è¯Šæ–­æŠ¥å‘Š")
        print(f"{'='*70}")
        
        stats = self.brake_analyzer.get_statistics()
        
        print(f"\nğŸ“Š åˆ¹è½¦è¡Œä¸ºåˆ†æ:")
        print(f"   â€¢ æ€»å¸§æ•°: {stats.get('total_frames', 0)}")
        print(f"   â€¢ åˆ¹è½¦å¸§å æ¯”: {stats.get('brake_ratio', 0)*100:.1f}%")
        print(f"   â€¢ æ€¥åˆ¹è½¦å¸§å æ¯”: {stats.get('hard_brake_ratio', 0)*100:.1f}%")
        print(f"   â€¢ å¹³å‡åˆ¹è½¦å€¼: {stats.get('avg_brake', 0):.3f}")
        
        # è¯Šæ–­å»ºè®®
        print(f"\nğŸ” è¯Šæ–­å»ºè®®:")
        
        brake_ratio = stats.get('brake_ratio', 0)
        if brake_ratio < 0.05:
            print("   âš ï¸ åˆ¹è½¦å¸§å æ¯”è¿‡ä½ (<5%)ï¼Œæ¨¡å‹å¯èƒ½æ²¡æœ‰å­¦ä¼šåˆ¹è½¦è¡Œä¸º")
            print("   å»ºè®®: æ£€æŸ¥è®­ç»ƒæ•°æ®ä¸­åˆ¹è½¦æ ·æœ¬çš„æ¯”ä¾‹å’Œè´¨é‡")
        elif brake_ratio < 0.15:
            print("   âš ï¸ åˆ¹è½¦å¸§å æ¯”åä½ï¼Œæ¨¡å‹åˆ¹è½¦è¡Œä¸ºå¯èƒ½ä¸å¤Ÿç§¯æ")
        else:
            print("   âœ… åˆ¹è½¦å¸§å æ¯”æ­£å¸¸")
        
        avg_brake = stats.get('avg_brake', 0)
        if avg_brake < 0.1:
            print("   âš ï¸ å¹³å‡åˆ¹è½¦å€¼è¿‡ä½ï¼Œæ¨¡å‹åˆ¹è½¦åŠ›åº¦ä¸è¶³")
        
        print(f"\nğŸ“ è¯Šæ–­ç»“æœå·²ä¿å­˜åˆ°: {self.save_dir}")
        print(f"{'='*70}\n")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("æ­£åœ¨æ¸…ç†èµ„æº...")
        
        # æ¸…ç†å¯è§£é‡Šæ€§æ¨¡å—ï¼ˆé‡Šæ”¾é’©å­å’Œå†…å­˜ï¼‰
        if hasattr(self, 'grad_cam') and self.grad_cam is not None:
            self.grad_cam.cleanup()
            print("  - GradCAM å·²æ¸…ç†")
        
        if hasattr(self, 'interp_viz') and self.interp_viz is not None:
            self.interp_viz.cleanup()
            print("  - å¯è§£é‡Šæ€§å¯è§†åŒ–å™¨å·²æ¸…ç†")
        
        if self.sensor_manager:
            self.sensor_manager.cleanup()
        
        if self.vehicle:
            self.vehicle.destroy()
        
        if self.world:
            settings = self.world.get_settings()
            settings.synchronous_mode = False
            self.world.apply_settings(settings)
        
        print("æ¸…ç†å®Œæˆï¼")


def main():
    parser = argparse.ArgumentParser(description='çº¢ç»¿ç¯åœºæ™¯è¯Šæ–­å·¥å…·')
    
    parser.add_argument('--model-path', type=str, required=True,
                        help='æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--net-structure', type=int, default=2,
                        help='ç½‘ç»œç»“æ„ç±»å‹')
    parser.add_argument('--gpu', type=int, default=0,
                        help='GPU ID')
    parser.add_argument('--host', type=str, default='localhost',
                        help='CARLA æœåŠ¡å™¨åœ°å€')
    parser.add_argument('--port', type=int, default=2000,
                        help='CARLA æœåŠ¡å™¨ç«¯å£')
    parser.add_argument('--town', type=str, default='Town01',
                        help='åœ°å›¾åç§°')
    parser.add_argument('--spawn-index', type=int, default=None,
                        help='èµ·ç‚¹ç´¢å¼•')
    parser.add_argument('--dest-index', type=int, default=None,
                        help='ç»ˆç‚¹ç´¢å¼•')
    parser.add_argument('--duration', type=int, default=120,
                        help='è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰')
    parser.add_argument('--save-dir', type=str, default='./diagnose_output',
                        help='ä¿å­˜ç›®å½•')
    parser.add_argument('--save-interval', type=int, default=30,
                        help='è‡ªåŠ¨ä¿å­˜é—´éš”ï¼ˆå¸§ï¼‰')
    
    args = parser.parse_args()
    
    # å¤„ç†æ¨¡å‹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    if not os.path.isabs(args.model_path):
        args.model_path = os.path.join(script_dir, args.model_path)
    
    # åˆ›å»ºè¯Šæ–­å™¨
    diagnoser = TrafficLightDiagnoser(
        model_path=args.model_path,
        host=args.host,
        port=args.port,
        town=args.town,
        gpu_id=args.gpu,
        save_dir=args.save_dir
    )
    
    try:
        diagnoser.load_model(args.net_structure)
        diagnoser.connect_carla()
        diagnoser.spawn_vehicle(args.spawn_index, args.dest_index)
        
        time.sleep(1.0)
        
        diagnoser.run_diagnosis(
            duration=args.duration,
            save_interval=args.save_interval
        )
        
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        diagnoser.cleanup()


if __name__ == '__main__':
    main()
