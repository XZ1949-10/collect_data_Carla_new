#!/usr/bin/env python
# coding=utf-8
'''
TurtleBot DDP æ•°æ®åŠ è½½å™¨ (å›ºå®šå¸§æ•°ç‰ˆæœ¬)

ç‰¹ç‚¹:
- æ”¯æŒåˆ†å¸ƒå¼é‡‡æ ·å’Œé¢„å–ä¼˜åŒ–
- åŠ è½½ linear_vel å’Œ angular_vel (è€Œä¸æ˜¯ steer, throttle, brake)
- ä¸ turtlebot_collect æ•°æ®æ ¼å¼å…¼å®¹

æ•°æ®æ ¼å¼:
    H5 æ–‡ä»¶ç»“æ„:
    {
        'rgb': (N, 88, 200, 3),      # å›¾åƒæ•°æ®
        'targets': (N, 25),          # æ§åˆ¶ä¿¡å·
    }
    
    targets å‘é‡:
        targets[10] = speed (km/h)
        targets[20] = linear_vel (m/s)
        targets[21] = angular_vel (rad/s)
        targets[24] = command (2/3/4/5)
'''

import glob
import os

import numpy as np
import h5py
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler

from imgaug import augmenters as iaa
from helper import RandomTransWrapper


# ============ é…ç½®å¸¸é‡ ============
# targets å‘é‡ç´¢å¼• (ä¸ turtlebot_collect/config/command_config.py ä¸€è‡´)
TARGETS_SPEED_IDX = 10
TARGETS_LINEAR_VEL_IDX = 20
TARGETS_ANGULAR_VEL_IDX = 21
TARGETS_COMMAND_IDX = 24

# æ¯ä¸ªåˆ†æ”¯çš„è¾“å‡ºç»´åº¦
BRANCH_OUTPUT_DIM = 2  # [linear_vel, angular_vel]

# åˆ†æ”¯æ•°é‡
NUM_BRANCHES = 4

# å½’ä¸€åŒ–å‚æ•°
SPEED_NORMALIZATION = 25.0  # é€Ÿåº¦å½’ä¸€åŒ–å› å­ (km/h)
MAX_LINEAR_VEL = 0.7        # æœ€å¤§çº¿é€Ÿåº¦ (m/s)ï¼Œç”¨äºå½’ä¸€åŒ–
MAX_ANGULAR_VEL = 1.0       # æœ€å¤§è§’é€Ÿåº¦ (rad/s)ï¼Œç”¨äºå½’ä¸€åŒ–


class CarlaH5DataDDP():
    """
    æ”¯æŒ DDP çš„ TurtleBot æ•°æ®åŠ è½½å™¨ (å›ºå®šå¸§æ•°ç‰ˆæœ¬)
    
    æ³¨æ„: ç±»åä¿æŒ CarlaH5DataDDP ä»¥å…¼å®¹ main_ddp.py
    """
    def __init__(self,
                 train_folder,
                 eval_folder,
                 batch_size=4,
                 num_workers=4,
                 distributed=False,
                 world_size=1,
                 rank=0,
                 prefetch_factor=2,
                 use_cache=False):
        
        train_dataset = TurtleBotH5Dataset(
            data_dir=train_folder,
            train_eval_flag="train",
            use_cache=use_cache)
        
        eval_dataset = TurtleBotH5Dataset(
            data_dir=eval_folder,
            train_eval_flag="eval",
            use_cache=use_cache)
        
        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
        if rank == 0:
            print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_dataset.data_list)} ä¸ªæ–‡ä»¶, {len(train_dataset)} å¸§")
            print(f"ğŸ“Š éªŒè¯é›†: {len(eval_dataset.data_list)} ä¸ªæ–‡ä»¶, {len(eval_dataset)} å¸§")
            print(f"ğŸ“Š è¾“å‡ºæ ¼å¼: [linear_vel, angular_vel] Ã— 4 åˆ†æ”¯ = 8 ç»´")
        
        # åˆ†å¸ƒå¼é‡‡æ ·å™¨
        if distributed:
            train_sampler = DistributedSampler(
                train_dataset,
                num_replicas=world_size,
                rank=rank,
                shuffle=True,
                drop_last=True)
            eval_sampler = DistributedSampler(
                eval_dataset,
                num_replicas=world_size,
                rank=rank,
                shuffle=False,
                drop_last=False)
        else:
            train_sampler = None
            eval_sampler = None
        
        self.samplers = {
            "train": train_sampler,
            "eval": eval_sampler
        }
        
        # ä¼˜åŒ–çš„ DataLoader é…ç½®
        loader_kwargs = {
            'pin_memory': True,
            'prefetch_factor': prefetch_factor if num_workers > 0 else None,
            'persistent_workers': num_workers > 0,
            'multiprocessing_context': 'spawn' if num_workers > 0 else None,
        }
        
        self.loaders = {
            "train": DataLoader(
                train_dataset,
                batch_size=batch_size,
                shuffle=(train_sampler is None),
                num_workers=num_workers,
                sampler=train_sampler,
                drop_last=True,
                **loader_kwargs
            ),
            "eval": DataLoader(
                eval_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                sampler=eval_sampler,
                **loader_kwargs
            )
        }


class TurtleBotH5Dataset(Dataset):
    """
    TurtleBot H5 æ•°æ®é›† (å›ºå®šå¸§æ•°ç‰ˆæœ¬)
    
    ç‰¹ç‚¹:
    - å‡è®¾æ¯ä¸ª h5 æ–‡ä»¶æœ‰å›ºå®šå¸§æ•° (sequence_len)
    - åŠ è½½ linear_vel å’Œ angular_vel
    """
    def __init__(self, data_dir, train_eval_flag="train", sequence_len=200, use_cache=False):
        self.data_dir = data_dir
        if not data_dir.endswith(('/', '\\')):
            data_dir = data_dir + '/'
        self.data_list = glob.glob(data_dir + '*.h5')
        self.data_list.sort()
        self.sequence_len = sequence_len
        self.train_eval_flag = train_eval_flag
        self.use_cache = use_cache
        
        # å†…å­˜ç¼“å­˜ (å¯é€‰)
        self._cache = {} if use_cache else None
        
        self.build_transform()

    def build_transform(self):
        """æ„å»ºæ•°æ®å¢å¼ºå˜æ¢"""
        if self.train_eval_flag == "train":
            self.transform = transforms.Compose([
                transforms.RandomOrder([
                    RandomTransWrapper(
                        seq=iaa.GaussianBlur((0, 1.5)),
                        p=0.09),
                    RandomTransWrapper(
                        seq=iaa.AdditiveGaussianNoise(
                            loc=0, scale=(0.0, 0.05), per_channel=0.5),
                        p=0.09),
                    RandomTransWrapper(
                        seq=iaa.Dropout((0.0, 0.10), per_channel=0.5),
                        p=0.3),
                    RandomTransWrapper(
                        seq=iaa.CoarseDropout(
                            (0.0, 0.10), size_percent=(0.08, 0.2), per_channel=0.5),
                        p=0.3),
                    RandomTransWrapper(
                        seq=iaa.Add((-20, 20), per_channel=0.5),
                        p=0.3),
                    RandomTransWrapper(
                        seq=iaa.Multiply((0.9, 1.1), per_channel=0.2),
                        p=0.4),
                    RandomTransWrapper(
                        seq=iaa.ContrastNormalization((0.8, 1.2), per_channel=0.5),
                        p=0.09),
                ]),
                transforms.ToTensor()])
        else:
            self.transform = transforms.Compose([transforms.ToTensor()])

    def __len__(self):
        return self.sequence_len * len(self.data_list)

    def __getitem__(self, idx):
        # æ£€æŸ¥ç¼“å­˜
        if self._cache is not None and idx in self._cache:
            cached = self._cache[idx]
            img = self.transform(cached['img'].copy())
            return img, cached['speed'], cached['target'], cached['mask']
        
        data_idx = idx // self.sequence_len
        file_idx = idx % self.sequence_len
        file_name = self.data_list[data_idx]

        # è¯»å–æ•°æ®
        with h5py.File(file_name, 'r') as h5_file:
            img = np.array(h5_file['rgb'][file_idx])
            target = np.array(h5_file['targets'][file_idx]).astype(np.float32)
        
        # å¤„ç†å‘½ä»¤
        # 2 Follow lane, 3 Left, 4 Right, 5 Straight
        # -> 0 Follow lane, 1 Left, 2 Right, 3 Straight
        command = int(target[TARGETS_COMMAND_IDX]) - 2
        command = max(0, min(3, command))  # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
        
        # æå– linear_vel å’Œ angular_vel
        linear_vel = target[TARGETS_LINEAR_VEL_IDX]
        angular_vel = target[TARGETS_ANGULAR_VEL_IDX]
        
        # å½’ä¸€åŒ–é€Ÿåº¦æ§åˆ¶ä¿¡å·
        linear_vel_norm = np.clip(linear_vel / MAX_LINEAR_VEL, -1.0, 1.0)
        angular_vel_norm = np.clip(angular_vel / MAX_ANGULAR_VEL, -1.0, 1.0)
        
        # æ„å»ºç›®æ ‡å‘é‡ (4ä¸ªåˆ†æ”¯ Ã— 2ç»´)
        target_vec = np.zeros((NUM_BRANCHES, BRANCH_OUTPUT_DIM), dtype=np.float32)
        target_vec[command, 0] = linear_vel_norm   # çº¿é€Ÿåº¦
        target_vec[command, 1] = angular_vel_norm  # è§’é€Ÿåº¦
        
        # é€Ÿåº¦è¾“å…¥ (å½’ä¸€åŒ–)
        speed = np.array([target[TARGETS_SPEED_IDX] / SPEED_NORMALIZATION], dtype=np.float32)
        
        # æ©ç å‘é‡
        mask_vec = np.zeros((NUM_BRANCHES, BRANCH_OUTPUT_DIM), dtype=np.float32)
        mask_vec[command, :] = 1
        
        # ç¼“å­˜åŸå§‹æ•°æ®
        if self._cache is not None:
            self._cache[idx] = {
                'img': img,
                'speed': speed,
                'target': target_vec.reshape(-1),
                'mask': mask_vec.reshape(-1)
            }
        
        img = self.transform(img)
        return img, speed, target_vec.reshape(-1), mask_vec.reshape(-1)


# ============ å…¼å®¹æ€§åˆ«å ============
CarlaH5Dataset = TurtleBotH5Dataset
