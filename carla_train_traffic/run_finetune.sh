#!/bin/bash
# ============================================================
# çº¢ç»¿ç¯åœºæ™¯é˜²é—å¿˜å¾®è°ƒå¯åŠ¨è„šæœ¬
# ============================================================
# 
# åŠŸèƒ½è¯´æ˜:
#   åœ¨å·²è®­ç»ƒå¥½çš„æ¨¡å‹åŸºç¡€ä¸Šï¼Œä½¿ç”¨çº¢ç»¿ç¯åœºæ™¯æ•°æ®è¿›è¡Œå¾®è°ƒ
#   åŒæ—¶é˜²æ­¢æ¨¡å‹é—å¿˜ä¹‹å‰å­¦ä¹ çš„é©¾é©¶çŸ¥è¯†
#
# é˜²é—å¿˜ç­–ç•¥:
#   1. æ··åˆæ•°æ®è®­ç»ƒ - æ–°æ—§æ•°æ®æŒ‰æ¯”ä¾‹æ··åˆ
#   2. çŸ¥è¯†è’¸é¦ - ç”¨æ—§æ¨¡å‹è¾“å‡ºä½œä¸ºè½¯æ ‡ç­¾
#
# ä½¿ç”¨æ–¹æ³•:
#   ./run_finetune.sh                           # ä½¿ç”¨é»˜è®¤é…ç½®
#   ./run_finetune.sh --mix-ratio 0.4           # è°ƒæ•´æ–°æ•°æ®å æ¯”ä¸º40%
#   ./run_finetune.sh --distill-alpha 0.5       # è°ƒæ•´è’¸é¦æŸå¤±æƒé‡
#   ./run_finetune.sh --lr 1e-5                 # è°ƒæ•´å­¦ä¹ ç‡
#   ./run_finetune.sh --epochs 50               # è°ƒæ•´è®­ç»ƒè½®æ•°
#
# ============================================================

# ============================================================
# GPUé…ç½®
# ============================================================
# æŒ‡å®šä½¿ç”¨çš„GPUç¼–å·ï¼Œæ ¹æ®ä½ çš„æœºå™¨ä¿®æ”¹
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5
NUM_GPUS=6  # GPUæ•°é‡ï¼Œéœ€è¦ä¸ä¸Šé¢çš„æ•°é‡ä¸€è‡´

# ============================================================
# è·¯å¾„é…ç½® - ã€å¿…é¡»ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„ã€‘
# ============================================================

# é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ - ä¹‹å‰è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹
PRETRAINED_MODEL="/path/to/your/best_model.pth"

# æ—§æ•°æ®è·¯å¾„ - åŸå§‹è®­ç»ƒæ•°æ®ï¼ˆç”¨äºæ··åˆè®­ç»ƒé˜²é—å¿˜ï¼‰
OLD_TRAIN_DIR="/path/to/original/train"
OLD_EVAL_DIR="/path/to/original/val"

# æ–°æ•°æ®è·¯å¾„ - çº¢ç»¿ç¯åœºæ™¯æ•°æ®
NEW_TRAIN_DIR="/path/to/traffic_light/train"
NEW_EVAL_DIR="/path/to/traffic_light/val"

# ============================================================
# ç¯å¢ƒå˜é‡é…ç½®
# ============================================================
export OMP_NUM_THREADS=4      # OpenMPçº¿ç¨‹æ•°
export NCCL_IB_DISABLE=1      # ç¦ç”¨InfiniBandï¼ˆæ— IBç½‘å¡æ—¶éœ€è¦ï¼‰
export NCCL_P2P_LEVEL=NVL     # NCCLç‚¹å¯¹ç‚¹é€šä¿¡çº§åˆ«

# ============================================================
# æ—¥å¿—é…ç½®
# ============================================================
LOG_DIR="logs"
mkdir -p $LOG_DIR
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="${LOG_DIR}/finetune_${TIMESTAMP}.log"

# æ‰“å°é…ç½®ä¿¡æ¯
echo "============================================================"
echo "ğŸš¦ çº¢ç»¿ç¯åœºæ™¯é˜²é—å¿˜å¾®è°ƒ"
echo "============================================================"
echo "é¢„è®­ç»ƒæ¨¡å‹: $PRETRAINED_MODEL"
echo "æ—§æ•°æ®è®­ç»ƒé›†: $OLD_TRAIN_DIR"
echo "æ–°æ•°æ®è®­ç»ƒé›†: $NEW_TRAIN_DIR"
echo "GPUæ•°é‡: $NUM_GPUS"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
echo "============================================================"
echo ""

# ============================================================
# å¯åŠ¨è®­ç»ƒ
# ============================================================
# å‚æ•°è¯´æ˜:
#   --pretrained        é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
#   --old-train-dir     æ—§æ•°æ®è®­ç»ƒé›†ç›®å½•ï¼ˆç”¨äºé˜²é—å¿˜ï¼‰
#   --old-eval-dir      æ—§æ•°æ®éªŒè¯é›†ç›®å½•
#   --new-train-dir     æ–°æ•°æ®è®­ç»ƒé›†ç›®å½•ï¼ˆçº¢ç»¿ç¯æ•°æ®ï¼‰
#   --new-eval-dir      æ–°æ•°æ®éªŒè¯é›†ç›®å½•
#   --batch-size        æ€»æ‰¹æ¬¡å¤§å°ï¼ˆä¼šè‡ªåŠ¨é™¤ä»¥GPUæ•°é‡ï¼‰
#   --workers           æ¯ä¸ªGPUçš„æ•°æ®åŠ è½½çº¿ç¨‹æ•°
#   --lr                å­¦ä¹ ç‡ï¼ˆå¾®è°ƒå»ºè®®ç”¨å°å­¦ä¹ ç‡ 1e-5 ~ 5e-5ï¼‰
#   --epochs            è®­ç»ƒè½®æ•°
#   --use-mixed-data    å¯ç”¨æ··åˆæ•°æ®è®­ç»ƒ
#   --mix-ratio         æ–°æ•°æ®å æ¯”ï¼ˆ0.3 = æ–°æ•°æ®30%ï¼Œæ—§æ•°æ®70%ï¼‰
#   --mix-mode          æ··åˆæ¨¡å¼ï¼šbalanced=å¹³è¡¡é‡‡æ ·ï¼Œconcat=ç®€å•æ‹¼æ¥
#   --use-distillation  å¯ç”¨çŸ¥è¯†è’¸é¦ï¼ˆç”¨æ—§æ¨¡å‹è¾“å‡ºä½œä¸ºè½¯æ ‡ç­¾ï¼‰
#   --distill-alpha     è’¸é¦æŸå¤±æƒé‡ï¼ˆ0.3 = 30%æŸå¤±æ¥è‡ªè’¸é¦ï¼‰
#   --early-stop        å¯ç”¨æ—©åœï¼ˆéªŒè¯lossä¸ä¸‹é™æ—¶æå‰åœæ­¢ï¼‰
#   --patience          æ—©åœè€å¿ƒå€¼ï¼ˆè¿ç»­Nè½®æ— æ”¹å–„åˆ™åœæ­¢ï¼‰
#   --channels-last     ä½¿ç”¨channels-lastå†…å­˜æ ¼å¼ï¼ˆGPUä¼˜åŒ–ï¼‰
#   --id                å®éªŒIDï¼ˆç”¨äºä¿å­˜æ¨¡å‹å’Œæ—¥å¿—ï¼‰

torchrun --nproc_per_node=$NUM_GPUS --master_port=29501 finetune_anti_forget.py \
    --pretrained "$PRETRAINED_MODEL" \
    --old-train-dir "$OLD_TRAIN_DIR" \
    --old-eval-dir "$OLD_EVAL_DIR" \
    --new-train-dir "$NEW_TRAIN_DIR" \
    --new-eval-dir "$NEW_EVAL_DIR" \
    --batch-size 768 \
    --workers 6 \
    --lr 5e-5 \
    --epochs 30 \
    --use-mixed-data \
    --mix-ratio 0.3 \
    --mix-mode balanced \
    --use-distillation \
    --distill-alpha 0.3 \
    --early-stop \
    --patience 8 \
    --channels-last \
    --id finetune_traffic_light_v1 \
    "$@" 2>&1 | tee $LOG_FILE

# ============================================================
# è®­ç»ƒå®Œæˆå
# ============================================================
# æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: save_models/finetune_traffic_light_v1_best.pth
# æ¯è½®æ¨¡å‹ä¿å­˜åœ¨: save_models/finetune_traffic_light_v1/epoch_N.pth
# è®­ç»ƒæ—¥å¿—ä¿å­˜åœ¨: logs/finetune_YYYYMMDD_HHMMSS.log
# TensorBoardæ—¥å¿—: runs/finetune_traffic_light_v1/
