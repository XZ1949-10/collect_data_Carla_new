#!/usr/bin/env python
# coding=utf-8
'''
é˜²é—å¿˜å¾®è°ƒè„šæœ¬
æ”¯æŒä¸‰ç§é˜²é—å¿˜ç­–ç•¥:
1. EWC (Elastic Weight Consolidation) - å¼¹æ€§æƒé‡å·©å›º
2. æ··åˆæ•°æ®è®­ç»ƒ - æ–°æ—§æ•°æ®æŒ‰æ¯”ä¾‹æ··åˆ
3. çŸ¥è¯†è’¸é¦ - ç”¨æ—§æ¨¡å‹è¾“å‡ºä½œä¸ºè½¯æ ‡ç­¾

ä½¿ç”¨æ–¹æ³•:
    # æ–¹å¼1: ä»…ä½¿ç”¨æ–°æ•°æ® + EWCé˜²é—å¿˜
    python finetune_anti_forget.py \
        --pretrained /path/to/best_model.pth \
        --new-train-dir /path/to/traffic_light/train \
        --new-eval-dir /path/to/traffic_light/val \
        --ewc-lambda 5000

    # æ–¹å¼2: æ··åˆæ–°æ—§æ•°æ®è®­ç»ƒ (æ¨è)
    python finetune_anti_forget.py \
        --pretrained /path/to/best_model.pth \
        --old-train-dir /path/to/original/train \
        --old-eval-dir /path/to/original/val \
        --new-train-dir /path/to/traffic_light/train \
        --new-eval-dir /path/to/traffic_light/val \
        --mix-ratio 0.3 \
        --use-mixed-data

    # æ–¹å¼3: çŸ¥è¯†è’¸é¦
    python finetune_anti_forget.py \
        --pretrained /path/to/best_model.pth \
        --new-train-dir /path/to/traffic_light/train \
        --new-eval-dir /path/to/traffic_light/val \
        --use-distillation \
        --distill-alpha 0.5

    # ç»„åˆä½¿ç”¨ (æœ€å¼ºé˜²é—å¿˜)
    python finetune_anti_forget.py \
        --pretrained /path/to/best_model.pth \
        --old-train-dir /path/to/original/train \
        --old-eval-dir /path/to/original/val \
        --new-train-dir /path/to/traffic_light/train \
        --new-eval-dir /path/to/traffic_light/val \
        --use-mixed-data --mix-ratio 0.3 \
        --use-distillation --distill-alpha 0.3 \
        --ewc-lambda 1000

åˆ†å¸ƒå¼è®­ç»ƒ:
    torchrun --nproc_per_node=6 finetune_anti_forget.py [å‚æ•°...]
'''
import argparse
import os
import copy
import random
import time
import datetime
import math
import logging

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.optim as optim
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.cuda.amp import autocast, GradScaler
from tensorboardX import SummaryWriter

from carla_net_ori import FinalNet
from carla_loader_dynamic import CarlaH5DataDDP
from carla_loader_mixed import MixedDataLoader
from helper import AverageMeter, save_checkpoint


parser = argparse.ArgumentParser(description='Anti-Forgetting Fine-tuning')

# æ¨¡å‹å‚æ•°
parser.add_argument('--pretrained', required=True, type=str,
                    help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
parser.add_argument('--net-structure', default=1, type=int,
                    help='ç½‘ç»œç»“æ„ 1|2|3')

# æ•°æ®å‚æ•°
parser.add_argument('--old-train-dir', default='', type=str,
                    help='æ—§æ•°æ®è®­ç»ƒé›†è·¯å¾„ (ç”¨äºæ··åˆè®­ç»ƒ)')
parser.add_argument('--old-eval-dir', default='', type=str,
                    help='æ—§æ•°æ®éªŒè¯é›†è·¯å¾„')
parser.add_argument('--new-train-dir', required=True, type=str,
                    help='æ–°æ•°æ®(çº¢ç»¿ç¯)è®­ç»ƒé›†è·¯å¾„')
parser.add_argument('--new-eval-dir', required=True, type=str,
                    help='æ–°æ•°æ®éªŒè¯é›†è·¯å¾„')
parser.add_argument('--min-frames', default=10, type=int,
                    help='æ¯ä¸ªh5æ–‡ä»¶æœ€å°å¸§æ•°')

# æ··åˆæ•°æ®å‚æ•°
parser.add_argument('--use-mixed-data', action='store_true', default=False,
                    help='ä½¿ç”¨æ–°æ—§æ•°æ®æ··åˆè®­ç»ƒ')
parser.add_argument('--mix-ratio', default=0.5, type=float,
                    help='æ–°æ•°æ®å æ¯” (0.3 = æ–°æ•°æ®30%, æ—§æ•°æ®70%)')
parser.add_argument('--mix-mode', default='balanced', type=str,
                    choices=['concat', 'balanced'],
                    help='æ··åˆæ¨¡å¼: concat=ç®€å•æ‹¼æ¥, balanced=å¹³è¡¡é‡‡æ ·')

# EWCå‚æ•°
parser.add_argument('--ewc-lambda', default=0, type=float,
                    help='EWCæ­£åˆ™åŒ–å¼ºåº¦ (0=ç¦ç”¨, æ¨è1000-10000)')
parser.add_argument('--ewc-samples', default=2000, type=int,
                    help='è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µçš„æ ·æœ¬æ•°')

# çŸ¥è¯†è’¸é¦å‚æ•°
parser.add_argument('--use-distillation', action='store_true', default=False,
                    help='ä½¿ç”¨çŸ¥è¯†è’¸é¦')
parser.add_argument('--distill-alpha', default=0.5, type=float,
                    help='è’¸é¦æŸå¤±æƒé‡ (0-1, è¶Šå¤§è¶Šä¿å®ˆ)')
parser.add_argument('--distill-temperature', default=2.0, type=float,
                    help='è’¸é¦æ¸©åº¦ (è¶Šé«˜è¶Šè½¯)')

# è®­ç»ƒå‚æ•°
parser.add_argument('-j', '--workers', default=4, type=int,
                    help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
parser.add_argument('-b', '--batch-size', default=256, type=int,
                    help='æ€»batch size')
parser.add_argument('--epochs', default=30, type=int,
                    help='è®­ç»ƒè½®æ•°')
parser.add_argument('--lr', default=5e-5, type=float,
                    help='å­¦ä¹ ç‡ (å¾®è°ƒåº”è¯¥æ¯”é¢„è®­ç»ƒå°)')
parser.add_argument('--speed-weight', default=0.5, type=float,
                    help='é€Ÿåº¦æŸå¤±æƒé‡')
parser.add_argument('--branch-weight', default=1.5, type=float,
                    help='åˆ†æ”¯æŸå¤±æƒé‡')
parser.add_argument('--weight-decay', default=1e-4, type=float,
                    help='æƒé‡è¡°å‡')

# å­¦ä¹ ç‡è°ƒåº¦
parser.add_argument('--lr-patience', default=3, type=int,
                    help='å­¦ä¹ ç‡è°ƒåº¦è€å¿ƒå€¼')
parser.add_argument('--lr-factor', default=0.5, type=float,
                    help='å­¦ä¹ ç‡è¡°å‡å› å­')
parser.add_argument('--min-lr', default=1e-7, type=float,
                    help='æœ€å°å­¦ä¹ ç‡')

# æ—©åœ
parser.add_argument('--early-stop', action='store_true', default=True,
                    help='å¯ç”¨æ—©åœ')
parser.add_argument('--patience', default=8, type=int,
                    help='æ—©åœè€å¿ƒå€¼')

# å…¶ä»–
parser.add_argument('--id', default='finetune_traffic_light', type=str,
                    help='å®éªŒID')
parser.add_argument('--print-freq', default=10, type=int,
                    help='æ‰“å°é¢‘ç‡')
parser.add_argument('--seed', default=42, type=int,
                    help='éšæœºç§å­')
parser.add_argument('--use-amp', action='store_true', default=False,
                    help='ä½¿ç”¨æ··åˆç²¾åº¦')
parser.add_argument('--channels-last', action='store_true', default=False,
                    help='ä½¿ç”¨channels_lastå†…å­˜æ ¼å¼')


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    def __init__(self, patience=8, min_delta=1e-4):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        
    def __call__(self, score):
        if self.best_score is None:
            self.best_score = score
            return False
        if score < self.best_score - self.min_delta:
            self.best_score = score
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
                return True
        return False


class EWC:
    """
    Elastic Weight Consolidation (å¼¹æ€§æƒé‡å·©å›º)
    
    æ ¸å¿ƒæ€æƒ³: åœ¨å¾®è°ƒæ—¶ï¼Œå¯¹é‡è¦å‚æ•°æ–½åŠ çº¦æŸï¼Œé˜²æ­¢å…¶åç¦»å¤ªè¿œ
    é‡è¦æ€§é€šè¿‡Fisherä¿¡æ¯çŸ©é˜µä¼°è®¡
    """
    def __init__(self, model, dataloader, device, num_samples=2000):
        self.model = model
        self.device = device
        self.params = {n: p.clone().detach() for n, p in model.named_parameters() if p.requires_grad}
        self.fisher = self._compute_fisher(dataloader, num_samples)
    
    def _compute_fisher(self, dataloader, num_samples):
        """è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µ (å¯¹è§’è¿‘ä¼¼)"""
        fisher = {n: torch.zeros_like(p) for n, p in self.model.named_parameters() if p.requires_grad}
        
        self.model.eval()
        samples_seen = 0
        
        for img, speed, target, mask in dataloader:
            if samples_seen >= num_samples:
                break
            
            img = img.to(self.device)
            speed = speed.to(self.device)
            target = target.to(self.device)
            mask = mask.to(self.device)
            
            self.model.zero_grad()
            
            output = self.model(img, speed)
            if isinstance(output, tuple) and len(output) == 4:
                branches_out, pred_speed, _, _ = output
            else:
                branches_out, pred_speed = output
            
            # ä½¿ç”¨è¾“å‡ºçš„logæ¦‚ç‡ä½œä¸ºæŸå¤±
            loss = F.mse_loss(branches_out * mask, target) + F.mse_loss(pred_speed, speed)
            loss.backward()
            
            for n, p in self.model.named_parameters():
                if p.requires_grad and p.grad is not None:
                    fisher[n] += p.grad.data.pow(2)
            
            samples_seen += img.size(0)
        
        # å½’ä¸€åŒ–
        for n in fisher:
            fisher[n] /= samples_seen
        
        return fisher
    
    def penalty(self, model):
        """è®¡ç®—EWCæƒ©ç½šé¡¹"""
        loss = 0
        for n, p in model.named_parameters():
            if p.requires_grad and n in self.fisher:
                loss += (self.fisher[n] * (p - self.params[n]).pow(2)).sum()
        return loss


class KnowledgeDistillation:
    """
    çŸ¥è¯†è’¸é¦
    
    ä½¿ç”¨æ—§æ¨¡å‹çš„è¾“å‡ºä½œä¸ºè½¯æ ‡ç­¾ï¼Œå¼•å¯¼æ–°æ¨¡å‹å­¦ä¹ 
    """
    def __init__(self, teacher_model, temperature=2.0, alpha=0.5):
        self.teacher = teacher_model
        self.teacher.eval()
        for p in self.teacher.parameters():
            p.requires_grad = False
        self.temperature = temperature
        self.alpha = alpha  # è’¸é¦æŸå¤±æƒé‡
    
    def distill_loss(self, student_output, img, speed, device):
        """è®¡ç®—è’¸é¦æŸå¤±"""
        with torch.no_grad():
            teacher_output = self.teacher(img, speed)
            if isinstance(teacher_output, tuple) and len(teacher_output) == 4:
                teacher_control, teacher_speed, _, _ = teacher_output
            else:
                teacher_control, teacher_speed = teacher_output
        
        if isinstance(student_output, tuple) and len(student_output) == 4:
            student_control, student_speed, _, _ = student_output
        else:
            student_control, student_speed = student_output
        
        # è½¯æ ‡ç­¾æŸå¤± (MSE for regression)
        control_distill = F.mse_loss(student_control, teacher_control)
        speed_distill = F.mse_loss(student_speed, teacher_speed)
        
        return control_distill + speed_distill


def setup_distributed():
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
        torch.cuda.set_device(local_rank)
        dist.init_process_group(backend='nccl', init_method='env://',
                                world_size=world_size, rank=rank)
        dist.barrier()
        return True, rank, world_size, local_rank
    return False, 0, 1, 0


def cleanup_distributed():
    if dist.is_initialized():
        dist.destroy_process_group()


def is_main_process(rank):
    return rank == 0


def output_log(msg, logger=None, rank=0):
    if rank == 0:
        print(f"[{datetime.datetime.now()}]: {msg}")
        if logger:
            logger.critical(f"[{datetime.datetime.now()}]: {msg}")


def reduce_tensor(tensor, world_size):
    rt = tensor.clone()
    dist.all_reduce(rt, op=dist.ReduceOp.SUM)
    rt /= world_size
    return rt


def load_pretrained_weights(model, checkpoint_path, rank=0):
    """åŠ è½½é¢„è®­ç»ƒæƒé‡"""
    output_log(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {checkpoint_path}", rank=rank)
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    state_dict = checkpoint.get('state_dict', checkpoint)
    
    # å¤„ç†DDPå‰ç¼€
    new_state_dict = {}
    for k, v in state_dict.items():
        new_key = k[7:] if k.startswith('module.') else k
        new_state_dict[new_key] = v
    
    model.load_state_dict(new_state_dict, strict=False)
    
    if 'epoch' in checkpoint:
        output_log(f"é¢„è®­ç»ƒæ¨¡å‹è®­ç»ƒäº† {checkpoint['epoch']} è½®", rank=rank)
    if 'best_prec' in checkpoint:
        output_log(f"é¢„è®­ç»ƒæ¨¡å‹æœ€ä½³loss: {checkpoint['best_prec']:.4f}", rank=rank)
    
    return model


def main():
    args = parser.parse_args()
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼
    distributed, rank, world_size, local_rank = setup_distributed()
    args.distributed = distributed
    args.rank = rank
    args.world_size = world_size
    args.local_rank = local_rank if distributed else 0
    
    # åˆ›å»ºç›®å½•
    log_dir = os.path.join("./logs", args.id)
    run_dir = os.path.join("./runs", args.id)
    save_weight_dir = os.path.join("./save_models", args.id)
    
    if is_main_process(rank):
        os.makedirs(log_dir, exist_ok=True)
        os.makedirs(save_weight_dir, exist_ok=True)
        logging.basicConfig(filename=os.path.join(log_dir, "finetune.log"),
                            level=logging.ERROR)
        tsbd = SummaryWriter(log_dir=run_dir)
        
        # æ‰“å°é…ç½®
        print("\n" + "="*70)
        print("ğŸš¦ çº¢ç»¿ç¯åœºæ™¯é˜²é—å¿˜å¾®è°ƒ")
        print("="*70)
        print(f"ğŸ“ é¢„è®­ç»ƒæ¨¡å‹: {args.pretrained}")
        print(f"ğŸ“ æ–°æ•°æ®è®­ç»ƒé›†: {args.new_train_dir}")
        print(f"ğŸ“ æ–°æ•°æ®éªŒè¯é›†: {args.new_eval_dir}")
        
        if args.use_mixed_data:
            print(f"\nğŸ”€ æ··åˆæ•°æ®è®­ç»ƒ:")
            print(f"   æ—§æ•°æ®è®­ç»ƒé›†: {args.old_train_dir}")
            print(f"   æ–°æ•°æ®å æ¯”: {args.mix_ratio*100:.0f}%")
            print(f"   æ··åˆæ¨¡å¼: {args.mix_mode}")
        
        if args.ewc_lambda > 0:
            print(f"\nğŸ›¡ï¸ EWCé˜²é—å¿˜:")
            print(f"   Lambda: {args.ewc_lambda}")
            print(f"   é‡‡æ ·æ•°: {args.ewc_samples}")
        
        if args.use_distillation:
            print(f"\nğŸ“š çŸ¥è¯†è’¸é¦:")
            print(f"   Alpha: {args.distill_alpha}")
            print(f"   Temperature: {args.distill_temperature}")
        
        print(f"\nâš™ï¸ è®­ç»ƒå‚æ•°:")
        print(f"   å­¦ä¹ ç‡: {args.lr}")
        print(f"   Batch Size: {args.batch_size}")
        print(f"   Epochs: {args.epochs}")
        print("="*70 + "\n")
    else:
        tsbd = None
        logging.basicConfig(level=logging.ERROR)
    
    # è®¾ç½®éšæœºç§å­
    if args.seed is not None:
        random.seed(args.seed + rank)
        torch.manual_seed(args.seed + rank)
        cudnn.deterministic = True
    
    # åˆ›å»ºæ¨¡å‹
    model = FinalNet(args.net_structure)
    model = load_pretrained_weights(model, args.pretrained, rank)
    
    # åˆ›å»ºæ•™å¸ˆæ¨¡å‹ (ç”¨äºçŸ¥è¯†è’¸é¦)
    teacher_model = None
    distiller = None
    if args.use_distillation:
        output_log("åˆ›å»ºæ•™å¸ˆæ¨¡å‹ç”¨äºçŸ¥è¯†è’¸é¦...", rank=rank)
        teacher_model = FinalNet(args.net_structure)
        teacher_model = load_pretrained_weights(teacher_model, args.pretrained, rank)
        teacher_model = teacher_model.cuda(args.local_rank)
        teacher_model.eval()
        distiller = KnowledgeDistillation(
            teacher_model, 
            temperature=args.distill_temperature,
            alpha=args.distill_alpha)
    
    model = model.cuda(args.local_rank)
    
    if args.channels_last:
        model = model.to(memory_format=torch.channels_last)
        if teacher_model:
            teacher_model = teacher_model.to(memory_format=torch.channels_last)
    
    # DDPåŒ…è£…
    if distributed:
        model = DDP(model, device_ids=[local_rank], output_device=local_rank,
                    find_unused_parameters=False)
    
    criterion = nn.MSELoss()
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.7, 0.85),
                           weight_decay=args.weight_decay)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=args.lr_factor,
        patience=args.lr_patience, min_lr=args.min_lr,
        verbose=is_main_process(rank))
    
    # æ—©åœ
    early_stopper = EarlyStopping(patience=args.patience) if args.early_stop else None
    
    # æ··åˆç²¾åº¦
    scaler = GradScaler() if args.use_amp else None
    
    best_prec = math.inf
    cudnn.benchmark = True
    
    # æ•°æ®åŠ è½½
    batch_size_per_gpu = args.batch_size // world_size
    
    if args.use_mixed_data and args.old_train_dir:
        # æ··åˆæ•°æ®åŠ è½½
        output_log("ä½¿ç”¨æ··åˆæ•°æ®åŠ è½½å™¨...", rank=rank)
        carla_data = MixedDataLoader(
            old_train_folder=args.old_train_dir,
            old_eval_folder=args.old_eval_dir,
            new_train_folder=args.new_train_dir,
            new_eval_folder=args.new_eval_dir,
            batch_size=batch_size_per_gpu,
            num_workers=args.workers,
            distributed=distributed,
            world_size=world_size,
            rank=rank,
            mix_ratio=args.mix_ratio,
            mix_mode=args.mix_mode,
            min_frames=args.min_frames)
    else:
        # ä»…æ–°æ•°æ®
        output_log("ä»…ä½¿ç”¨æ–°æ•°æ®è®­ç»ƒ...", rank=rank)
        carla_data = CarlaH5DataDDP(
            train_folder=args.new_train_dir,
            eval_folder=args.new_eval_dir,
            batch_size=batch_size_per_gpu,
            num_workers=args.workers,
            distributed=distributed,
            world_size=world_size,
            rank=rank,
            min_frames=args.min_frames)
    
    train_loader = carla_data.loaders["train"]
    train_sampler = carla_data.samplers["train"]
    eval_loader = carla_data.loaders["eval"]
    
    # EWCåˆå§‹åŒ– (åœ¨å¾®è°ƒå‰è®¡ç®—FisherçŸ©é˜µï¼Œè®°å½•å‚æ•°é‡è¦æ€§)
    ewc = None
    if args.ewc_lambda > 0:
        output_log(f"è®¡ç®—EWC Fisherä¿¡æ¯çŸ©é˜µ (é‡‡æ ·{args.ewc_samples}ä¸ªæ ·æœ¬)...", rank=rank)
        
        # é€‰æ‹©ç”¨äºè®¡ç®—Fisherçš„æ•°æ®
        if args.old_train_dir:
            # ä¼˜å…ˆä½¿ç”¨æ—§æ•°æ®è®¡ç®—Fisher (æœ€ä½³é€‰æ‹©)
            output_log("ä½¿ç”¨æ—§æ•°æ®è®¡ç®—FisherçŸ©é˜µ", rank=rank)
            ewc_loader = CarlaH5DataDDP(
                train_folder=args.old_train_dir,
                eval_folder=args.old_eval_dir,
                batch_size=batch_size_per_gpu,
                num_workers=args.workers,
                distributed=False,  # å•å¡è®¡ç®—
                world_size=1,
                rank=0,
                min_frames=args.min_frames).loaders["train"]
        else:
            # æ²¡æœ‰æ—§æ•°æ®æ—¶ï¼Œä½¿ç”¨æ–°æ•°æ®è®¡ç®—Fisher
            # è¿™ä¼šä¿æŠ¤æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„åˆå§‹è¡¨ç°ï¼Œé˜²æ­¢è¿‡åº¦æ‹Ÿåˆ
            output_log("âš ï¸ æ— æ—§æ•°æ®ï¼Œä½¿ç”¨æ–°æ•°æ®è®¡ç®—FisherçŸ©é˜µ", rank=rank)
            ewc_loader = CarlaH5DataDDP(
                train_folder=args.new_train_dir,
                eval_folder=args.new_eval_dir,
                batch_size=batch_size_per_gpu,
                num_workers=args.workers,
                distributed=False,
                world_size=1,
                rank=0,
                min_frames=args.min_frames).loaders["train"]
        
        # è·å–åŸå§‹æ¨¡å‹ (å»æ‰DDPåŒ…è£…)
        raw_model = model.module if distributed else model
        ewc = EWC(raw_model, ewc_loader, args.local_rank, args.ewc_samples)
        output_log("EWCåˆå§‹åŒ–å®Œæˆ", rank=rank)
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(args.epochs):
        if distributed and train_sampler:
            train_sampler.set_epoch(epoch)
        
        train_loss = train(
            train_loader, model, criterion, optimizer, epoch,
            tsbd, scaler, args, ewc=ewc, distiller=distiller)
        
        eval_loss = evaluate(eval_loader, model, criterion, epoch, tsbd, args)
        
        lr_scheduler.step(eval_loss)
        
        current_lr = optimizer.param_groups[0]['lr']
        if is_main_process(rank):
            output_log(f"Epoch {epoch+1} - Train: {train_loss:.4f}, "
                      f"Eval: {eval_loss:.4f}, LR: {current_lr:.2e}", rank=rank)
            if tsbd:
                tsbd.add_scalar('finetune/learning_rate', current_lr, epoch + 1)
        
        # ä¿å­˜æ¨¡å‹
        if is_main_process(rank):
            is_best = eval_loss < best_prec
            best_prec = min(eval_loss, best_prec)
            save_checkpoint(
                {'epoch': epoch + 1,
                 'state_dict': model.state_dict(),
                 'best_prec': best_prec,
                 'optimizer': optimizer.state_dict(),
                 'scheduler': lr_scheduler.state_dict()},
                args.id, is_best,
                os.path.join(save_weight_dir, f"epoch_{epoch+1}.pth"))
        
        # æ—©åœ
        if early_stopper and early_stopper(eval_loss):
            output_log(f"æ—©åœè§¦å‘äº epoch {epoch+1}!", rank=rank)
            break
        
        if distributed:
            dist.barrier()
    
    if is_main_process(rank):
        print("\n" + "="*70)
        print(f"âœ… å¾®è°ƒå®Œæˆ! æœ€ä½³éªŒè¯loss: {best_prec:.4f}")
        print(f"ğŸ“ æœ€ä½³æ¨¡å‹ä¿å­˜è‡³: save_models/{args.id}_best.pth")
        print("="*70)
    
    cleanup_distributed()


def train(loader, model, criterion, optimizer, epoch, writer, scaler, args,
          ewc=None, distiller=None):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    losses = AverageMeter()
    ewc_losses = AverageMeter()
    distill_losses = AverageMeter()
    
    model.train()
    
    for i, (img, speed, target, mask) in enumerate(loader):
        img = img.cuda(args.local_rank, non_blocking=True)
        speed = speed.cuda(args.local_rank, non_blocking=True)
        target = target.cuda(args.local_rank, non_blocking=True)
        mask = mask.cuda(args.local_rank, non_blocking=True)
        
        if args.channels_last:
            img = img.to(memory_format=torch.channels_last)
        
        optimizer.zero_grad()
        
        with autocast(enabled=args.use_amp):
            output = model(img, speed)
            if isinstance(output, tuple) and len(output) == 4:
                branches_out, pred_speed, log_var_control, log_var_speed = output
                branch_loss = torch.mean((torch.exp(-log_var_control)
                                          * torch.pow((branches_out - target), 2)
                                          + log_var_control) * 0.5 * mask) * 4
                speed_loss = torch.mean((torch.exp(-log_var_speed)
                                         * torch.pow((pred_speed - speed), 2)
                                         + log_var_speed) * 0.5)
            else:
                branches_out, pred_speed = output
                branch_loss = criterion(branches_out * mask, target) * 4
                speed_loss = criterion(pred_speed, speed)
            
            # åŸºç¡€æŸå¤±
            task_loss = args.branch_weight * branch_loss + args.speed_weight * speed_loss
            total_loss = task_loss
            
            # EWCæŸå¤±
            ewc_loss_val = 0
            if ewc is not None and args.ewc_lambda > 0:
                raw_model = model.module if args.distributed else model
                ewc_loss_val = ewc.penalty(raw_model)
                total_loss = total_loss + args.ewc_lambda * ewc_loss_val
            
            # è’¸é¦æŸå¤±
            distill_loss_val = 0
            if distiller is not None:
                distill_loss_val = distiller.distill_loss(output, img, speed, args.local_rank)
                total_loss = (1 - distiller.alpha) * total_loss + distiller.alpha * distill_loss_val
        
        if scaler:
            scaler.scale(total_loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            total_loss.backward()
            optimizer.step()
        
        # è®°å½•æŸå¤±
        if args.distributed:
            reduced_loss = reduce_tensor(task_loss.data, args.world_size)
        else:
            reduced_loss = task_loss.data
        
        losses.update(reduced_loss.item(), img.size(0))
        if ewc is not None:
            ewc_losses.update(ewc_loss_val.item() if isinstance(ewc_loss_val, torch.Tensor) else ewc_loss_val, img.size(0))
        if distiller is not None:
            distill_losses.update(distill_loss_val.item() if isinstance(distill_loss_val, torch.Tensor) else distill_loss_val, img.size(0))
        
        if i % args.print_freq == 0 and is_main_process(args.rank):
            extra_info = ""
            if ewc is not None:
                extra_info += f" EWC:{ewc_losses.val:.4f}"
            if distiller is not None:
                extra_info += f" Distill:{distill_losses.val:.4f}"
            output_log(f'Epoch [{epoch+1}][{i}/{len(loader)}] '
                      f'Loss {losses.val:.4f} ({losses.avg:.4f}){extra_info}', rank=args.rank)
    
    return losses.avg


def evaluate(loader, model, criterion, epoch, writer, args):
    """éªŒè¯"""
    losses = AverageMeter()
    model.eval()
    
    with torch.no_grad():
        for img, speed, target, mask in loader:
            img = img.cuda(args.local_rank, non_blocking=True)
            speed = speed.cuda(args.local_rank, non_blocking=True)
            target = target.cuda(args.local_rank, non_blocking=True)
            mask = mask.cuda(args.local_rank, non_blocking=True)
            
            output = model(img, speed)
            if isinstance(output, tuple) and len(output) == 4:
                branches_out, pred_speed, log_var_control, log_var_speed = output
                branch_loss = torch.mean((torch.exp(-log_var_control)
                                          * torch.pow((branches_out - target), 2)
                                          + log_var_control) * 0.5 * mask) * 4
                speed_loss = torch.mean((torch.exp(-log_var_speed)
                                         * torch.pow((pred_speed - speed), 2)
                                         + log_var_speed) * 0.5)
            else:
                branches_out, pred_speed = output
                branch_loss = criterion(branches_out * mask, target) * 4
                speed_loss = criterion(pred_speed, speed)
            
            loss = args.branch_weight * branch_loss + args.speed_weight * speed_loss
            
            if args.distributed:
                reduced_loss = reduce_tensor(loss.data, args.world_size)
            else:
                reduced_loss = loss.data
            
            losses.update(reduced_loss.item(), img.size(0))
    
    if is_main_process(args.rank) and writer:
        writer.add_scalar('finetune/eval_loss', losses.avg, epoch + 1)
    
    return losses.avg


if __name__ == '__main__':
    main()
