#!/usr/bin/env python
# coding=utf-8
'''
ä½œè€…: AI Assistant  
æ—¥æœŸ: 2025-11-03
è¯´æ˜: åŸºäºå‘½ä»¤åˆ†æ®µçš„äº¤äº’å¼æ•°æ®æ”¶é›†
      å½“å¯¼èˆªå‘½ä»¤å˜åŒ–æ—¶æš‚åœï¼Œè¯¢é—®ç”¨æˆ·æ˜¯å¦ä¿å­˜è¯¥æ®µæ•°æ®
      æ¯æ®µæ•°æ®æŒ‰200æ¡åˆ‡ç‰‡ä¿å­˜
'''

import os
import sys
import time
import numpy as np
import cv2

# å¯¼å…¥åŸºç±»
from base_collector import BaseDataCollector, AGENTS_AVAILABLE


class CommandBasedDataCollector(BaseDataCollector):
    """
    åŸºäºå‘½ä»¤åˆ†æ®µçš„æ•°æ®æ”¶é›†å™¨
    
    ç‰¹ç‚¹ï¼š
    1. æ£€æµ‹å¯¼èˆªå‘½ä»¤å˜åŒ–
    2. å‘½ä»¤å˜åŒ–æ—¶æš‚åœå¹¶è¯¢é—®æ˜¯å¦ä¿å­˜
    3. æ¯æ®µæ•°æ®æŒ‰200æ¡åˆ‡ç‰‡ä¿å­˜
    4. æ”¯æŒè·³è¿‡ä¸éœ€è¦çš„å‘½ä»¤æ®µ
    """
    
    def __init__(self, host='localhost', port=2000, town='Town01',
                 ignore_traffic_lights=True, ignore_signs=True, 
                 ignore_vehicles_percentage=80, target_speed=10.0, simulation_fps=20,
                 noise_enabled=False, lateral_noise=True, longitudinal_noise=False,
                 noise_ratio=0.4, max_steer_offset=0.35, max_throttle_offset=0.2,
                 noise_modes=None):
        super().__init__(host, port, town, ignore_traffic_lights, ignore_signs,
                        ignore_vehicles_percentage, target_speed, simulation_fps)
        
        # é…ç½®å™ªå£°å‚æ•°
        self.configure_noise(
            enabled=noise_enabled,
            lateral_enabled=lateral_noise,
            longitudinal_enabled=longitudinal_noise,
            noise_ratio=noise_ratio,
            max_steer_offset=max_steer_offset,
            max_throttle_offset=max_throttle_offset,
            noise_modes=noise_modes
        )
    
    def _ask_user_save_segment(self, command, show_visualization=False, 
                                current_image=None, speed=0.0, current_frame=0, total_frames=0):
        """
        è¯¢é—®ç”¨æˆ·æ˜¯å¦ä¿å­˜å½“å‰æ•°æ®æ®µ
        
        è¿”å›:
            bool: True=ä¿å­˜, False=ä¸¢å¼ƒ, None=åœæ­¢æ”¶é›†
        """
        if show_visualization and current_image is not None:
            self._visualize_frame(current_image, speed, command, current_frame, total_frames, 
                                paused=True, is_collecting=True)
        
        print("\n" + "="*70)
        print(f"â¸ï¸  è½¦è¾†å·²æš‚åœ - æ£€æµ‹åˆ°å‘½ä»¤: {self.COMMAND_NAMES.get(int(command), 'Unknown')} (å‘½ä»¤{command})")
        print("="*70)
        print(f"\nğŸ’¡ æç¤ºï¼šè½¦è¾†å·²åœæ­¢ï¼Œç­‰å¾…ä½ çš„æŒ‡ä»¤")
        print(f"è¯·é€‰æ‹©æ“ä½œ:")
        print(f"  âœ… 'ä¿å­˜' æˆ– 's' â†’ æ”¶é›†200å¸§ â†’ è‡ªåŠ¨ä¿å­˜")
        print(f"  âŒ 'è·³è¿‡' æˆ– 'n' â†’ è·³è¿‡æ­¤å‘½ä»¤æ®µï¼Œç­‰å¾…å‘½ä»¤å˜åŒ–")
        print(f"  â¹ï¸  'åœæ­¢' æˆ– 'q' â†’ åœæ­¢æ”¶é›†å¹¶é€€å‡º")
        
        while True:
            try:
                choice = input(f"\nğŸ‘‰ ä½ çš„é€‰æ‹©: ").strip().lower()
                
                if choice in ['ä¿å­˜', 'save', 's', 'y', 'yes']:
                    print(f"âœ… å°†ä¿å­˜è¿™æ®µæ•°æ®")
                    print(f"â–¶ï¸  è½¦è¾†ç»§ç»­è¡Œé©¶...\n")
                    return True
                elif choice in ['è·³è¿‡', 'skip', 'n', 'no']:
                    print(f"âŒ å°†ä¸¢å¼ƒè¿™æ®µæ•°æ®")
                    print(f"â–¶ï¸  è½¦è¾†ç»§ç»­è¡Œé©¶...\n")
                    return False
                elif choice in ['åœæ­¢', 'stop', 'q', 'quit']:
                    print(f"â¹ï¸  åœæ­¢æ”¶é›†")
                    return None
                else:
                    print(f"âŒ æ— æ•ˆé€‰æ‹©ï¼è¯·è¾“å…¥ 'ä¿å­˜' (s)ã€'è·³è¿‡' (n) æˆ– 'åœæ­¢' (q)")
                    
            except KeyboardInterrupt:
                print("\nâ¹ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·")
                return None
    
    def _save_segment(self, save_path, command):
        """ä¿å­˜å½“å‰æ•°æ®æ®µï¼ˆæŒ‰200æ¡åˆ‡ç‰‡ï¼‰"""
        if len(self.current_segment_data['rgb']) == 0:
            print("å½“å‰æ®µæ— æ•°æ®ï¼Œè·³è¿‡ä¿å­˜")
            return
        
        print(f"\næ­£åœ¨ä¿å­˜æ•°æ®æ®µ...")
        
        rgb_array = np.array(self.current_segment_data['rgb'], dtype=np.uint8)
        targets_array = np.array(self.current_segment_data['targets'], dtype=np.float32)
        
        total_samples = rgb_array.shape[0]
        num_chunks = (total_samples + 199) // 200
        print(f"  æ€»æ ·æœ¬æ•°: {total_samples}, åˆ†å‰²æˆ {num_chunks} ä¸ªæ–‡ä»¶")
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        command_name = self.COMMAND_NAMES.get(int(command), 'Unknown')
        
        for chunk_idx in range(num_chunks):
            start_idx = chunk_idx * 200
            end_idx = min((chunk_idx + 1) * 200, total_samples)
            
            chunk_rgb = rgb_array[start_idx:end_idx]
            chunk_targets = targets_array[start_idx:end_idx]
            
            self._save_data_to_h5(
                chunk_rgb.tolist(), chunk_targets.tolist(),
                save_path, command, f"_part{chunk_idx+1:03d}"
            )
        
        print(f"âœ… æ•°æ®æ®µä¿å­˜å®Œæˆï¼")
    
    def collect_data_interactive(self, max_frames=50000, save_path='./carla_data', visualize=True):
        """
        äº¤äº’å¼æ•°æ®æ”¶é›†
        
        å·¥ä½œæµç¨‹ï¼š
        1. è¯¢é—®æ˜¯å¦æ”¶é›†å½“å‰å‘½ä»¤æ®µ
        2. å¦‚æœé€‰æ‹©"ä¿å­˜"â†’ æ”¶é›†200å¸§ â†’ è‡ªåŠ¨ä¿å­˜
        3. è‡ªåŠ¨ä¿å­˜å â†’ ç»§ç»­è¯¢é—®ä¸‹ä¸€æ®µ
        """
        self.enable_visualization = visualize
        
        print("\n" + "="*70)
        print("ğŸ“Š åŸºäºå‘½ä»¤çš„äº¤äº’å¼æ•°æ®æ”¶é›†")
        print("="*70)
        print(f"æœ€å¤§å¸§æ•°: {max_frames}")
        print(f"ä¿å­˜è·¯å¾„: {save_path}")
        print(f"å¯è§†åŒ–: {'å¼€å¯' if visualize else 'å…³é—­'}")
        print("="*70)
        
        os.makedirs(save_path, exist_ok=True)
        self.wait_for_first_frame()
        
        collected_frames = 0
        self.current_segment_data = {'rgb': [], 'targets': []}
        self.segment_count = 0
        
        self.current_command = self._get_navigation_command()
        
        # è·å–åˆå§‹ç”»é¢
        for _ in range(10):
            self.step_simulation()
            time.sleep(0.05)
        
        print("\nå¼€å§‹æ•°æ®æ”¶é›†å¾ªç¯...")
        
        try:
            while collected_frames < max_frames:
                self.current_command = self._get_navigation_command()
                
                current_image = self.image_buffer[-1] if len(self.image_buffer) > 0 else None
                current_speed = self._get_vehicle_speed()
                
                # è¯¢é—®ç”¨æˆ·
                user_choice = self._ask_user_save_segment(
                    command=self.current_command,
                    show_visualization=self.enable_visualization,
                    current_image=current_image,
                    speed=current_speed,
                    current_frame=collected_frames,
                    total_frames=max_frames
                )
                
                if user_choice is None:
                    print("âœ… ç”¨æˆ·é€‰æ‹©åœæ­¢æ”¶é›†")
                    break
                
                if not user_choice:
                    # è·³è¿‡æ¨¡å¼ï¼šç­‰å¾…å‘½ä»¤å˜åŒ–
                    print(f"âŒ è·³è¿‡ {self.COMMAND_NAMES[int(self.current_command)]} å‘½ä»¤æ®µ")
                    collected_frames = self._skip_until_command_change(collected_frames, max_frames)
                    continue
                
                # æ”¶é›†200å¸§
                save_command = self.current_command
                print(f"âœ… å¼€å§‹æ”¶é›† {self.COMMAND_NAMES[int(save_command)]} å‘½ä»¤æ®µï¼ˆç›®æ ‡ï¼š200å¸§ï¼‰...")
                
                self.current_segment_data = {'rgb': [], 'targets': []}
                self.segment_count = 0
                collision_occurred = False  # ç¢°æ’æ ‡è®°
                
                # é‡ç½®ç¢°æ’çŠ¶æ€
                self.reset_collision_state()
                
                while self.segment_count < 200 and collected_frames < max_frames:
                    self.step_simulation()
                    
                    # æ£€æµ‹ç¢°æ’
                    if self.collision_detected:
                        print(f"ğŸ’¥ ç¢°æ’å‘ç”Ÿï¼ä¸¢å¼ƒå½“å‰segmentæ•°æ®ï¼ˆ{self.segment_count}å¸§ï¼‰")
                        collision_occurred = True
                        self.current_segment_data = {'rgb': [], 'targets': []}
                        self.segment_count = 0
                        break
                    
                    if self._is_route_completed():
                        print(f"\nğŸ¯ å·²åˆ°è¾¾ç›®çš„åœ°ï¼")
                        break
                    
                    if len(self.image_buffer) == 0:
                        continue
                    
                    current_image = self.image_buffer[-1].copy()
                    speed_kmh = self._get_vehicle_speed()
                    current_cmd = self._get_navigation_command()
                    
                    # æ•°æ®è´¨é‡æ£€æŸ¥
                    if current_image.mean() < 5 or speed_kmh > 150:
                        continue
                    
                    targets = self._build_targets(speed_kmh, current_cmd)
                    
                    self.current_segment_data['rgb'].append(current_image)
                    self.current_segment_data['targets'].append(targets)
                    self.segment_count += 1
                    collected_frames += 1
                    
                    if self.enable_visualization:
                        self._visualize_frame(current_image, speed_kmh, current_cmd,
                                            collected_frames, max_frames, is_collecting=True)
                    
                    if self.segment_count % 50 == 0:
                        print(f"  [æ”¶é›†ä¸­] è¿›åº¦: {self.segment_count}/200 å¸§")
                
                # è‡ªåŠ¨ä¿å­˜ï¼ˆå¦‚æœæ²¡æœ‰ç¢°æ’ï¼‰
                if self.segment_count > 0 and not collision_occurred:
                    print(f"\nğŸ’¾ è‡ªåŠ¨ä¿å­˜æ•°æ®æ®µï¼ˆ{self.segment_count} å¸§ï¼‰...")
                    self._save_segment(save_path, save_command)
                elif collision_occurred:
                    print(f"âš ï¸  å› ç¢°æ’è·³è¿‡ä¿å­˜ï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªå‘½ä»¤æ®µ...")
                
                if self._is_route_completed():
                    break
            
            self._print_summary(collected_frames)
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ”¶é›†...")
            if self.segment_count > 0:
                save_final = input(f"\nå½“å‰æ®µæœ‰ {self.segment_count} å¸§ï¼Œæ˜¯å¦ä¿å­˜ï¼Ÿ(y/n): ").strip().lower()
                if save_final in ['y', 'yes', 'ä¿å­˜']:
                    self._save_segment(save_path, self.current_command)
        
        finally:
            if self.enable_visualization:
                cv2.destroyAllWindows()
    
    def _skip_until_command_change(self, collected_frames, max_frames):
        """è·³è¿‡ç›´åˆ°å‘½ä»¤å˜åŒ–"""
        print("ğŸ”„ ç­‰å¾…å‘½ä»¤å˜åŒ–...")
        skip_frames = 0
        
        while skip_frames < 500:
            self.step_simulation()
            
            if self._is_route_completed():
                print(f"\nğŸ¯ å·²åˆ°è¾¾ç›®çš„åœ°ï¼")
                return collected_frames
            
            new_command = self._get_navigation_command()
            if new_command != self.current_command:
                print(f"âœ… å‘½ä»¤å·²å˜åŒ–: {self.COMMAND_NAMES.get(int(self.current_command), 'Unknown')} â†’ "
                      f"{self.COMMAND_NAMES.get(int(new_command), 'Unknown')}\n")
                break
            
            skip_frames += 1
            collected_frames += 1
            
            if self.enable_visualization and len(self.image_buffer) > 0:
                self._visualize_frame(self.image_buffer[-1], self._get_vehicle_speed(),
                                    new_command, collected_frames, max_frames, is_collecting=False)
        
        return collected_frames
    
    def _print_summary(self, collected_frames):
        """æ‰“å°æ”¶é›†æ€»ç»“"""
        print(f"\n{'='*70}")
        print(f"âœ… æ•°æ®æ”¶é›†å®Œæˆï¼")
        print(f"{'='*70}")
        print(f"æ€»æ”¶é›†å¸§æ•°: {collected_frames}")
        print(f"æ€»ä¿å­˜å¸§æ•°: {self.total_saved_frames}")
        print(f"ä¿å­˜æ®µæ•°: {self.total_saved_segments}")
        print(f"{'='*70}\n")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åŸºäºå‘½ä»¤çš„äº¤äº’å¼æ•°æ®æ”¶é›†')
    parser.add_argument('--host', type=str, default='localhost')
    parser.add_argument('--port', type=int, default=2000)
    parser.add_argument('--town', type=str, default='Town01')
    parser.add_argument('--spawn-index', type=int, required=True)
    parser.add_argument('--dest-index', type=int, required=True)
    parser.add_argument('--max-frames', type=int, default=50000)
    parser.add_argument('--save-path', type=str, default='./carla_data')
    parser.add_argument('--visualize', action='store_true')
    
    args = parser.parse_args()
    
    collector = CommandBasedDataCollector(args.host, args.port, args.town)
    
    try:
        collector.connect()
        
        if not collector.spawn_vehicle(args.spawn_index, args.dest_index):
            print("æ— æ³•ç”Ÿæˆè½¦è¾†ï¼")
            return
        
        collector.setup_camera()
        collector.setup_collision_sensor()  # è®¾ç½®ç¢°æ’ä¼ æ„Ÿå™¨
        time.sleep(1.0)
        
        collector.collect_data_interactive(
            max_frames=args.max_frames,
            save_path=args.save_path,
            visualize=args.visualize
        )
        
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        collector.cleanup()


if __name__ == '__main__':
    main()
