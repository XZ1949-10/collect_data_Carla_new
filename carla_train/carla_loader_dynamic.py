#!/usr/bin/env python
# coding=utf-8
'''
åŠ¨æ€å¸§æ•°ç‰ˆæœ¬çš„æ•°æ®åŠ è½½å™¨
æ”¯æŒä¸åŒå¸§æ•°çš„h5æ–‡ä»¶æ··åˆè®­ç»ƒ
é’ˆå¯¹P100å¤šå¡è®­ç»ƒä¼˜åŒ–
'''

import glob
import os

import numpy as np
import h5py
import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler

from imgaug import augmenters as iaa
from helper import RandomTransWrapper


class CarlaH5DataDDP():
    """æ”¯æŒDDPçš„æ•°æ®åŠ è½½å™¨ï¼ŒåŠ¨æ€å¸§æ•°ç‰ˆæœ¬"""
    def __init__(self,
                 train_folder,
                 eval_folder,
                 batch_size=4,
                 num_workers=4,
                 distributed=False,
                 world_size=1,
                 rank=0,
                 prefetch_factor=2,
                 use_cache=False,
                 min_frames=10):
        
        train_dataset = CarlaH5DatasetDynamic(
            data_dir=train_folder,
            train_eval_flag="train",
            use_cache=use_cache,
            min_frames=min_frames)
        
        eval_dataset = CarlaH5DatasetDynamic(
            data_dir=eval_folder,
            train_eval_flag="eval",
            use_cache=use_cache,
            min_frames=min_frames)
        
        # æ‰“å°æ•°æ®é›†ä¿¡æ¯
        if rank == 0:
            print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_dataset.data_list)} ä¸ªæ–‡ä»¶, {len(train_dataset)} å¸§")
            print(f"ğŸ“Š éªŒè¯é›†: {len(eval_dataset.data_list)} ä¸ªæ–‡ä»¶, {len(eval_dataset)} å¸§")
        
        # åˆ†å¸ƒå¼é‡‡æ ·å™¨
        if distributed:
            train_sampler = DistributedSampler(
                train_dataset,
                num_replicas=world_size,
                rank=rank,
                shuffle=True,
                drop_last=True)
            eval_sampler = DistributedSampler(
                eval_dataset,
                num_replicas=world_size,
                rank=rank,
                shuffle=False,
                drop_last=False)
        else:
            train_sampler = None
            eval_sampler = None
        
        self.samplers = {
            "train": train_sampler,
            "eval": eval_sampler
        }
        
        # ä¼˜åŒ–çš„DataLoaderé…ç½®
        loader_kwargs = {
            'pin_memory': True,
            'prefetch_factor': prefetch_factor if num_workers > 0 else None,
            'persistent_workers': num_workers > 0,
            'multiprocessing_context': 'spawn' if num_workers > 0 else None,
        }
        
        self.loaders = {
            "train": DataLoader(
                train_dataset,
                batch_size=batch_size,
                shuffle=(train_sampler is None),
                num_workers=num_workers,
                sampler=train_sampler,
                drop_last=True,
                **loader_kwargs
            ),
            "eval": DataLoader(
                eval_dataset,
                batch_size=batch_size,
                shuffle=False,
                num_workers=num_workers,
                sampler=eval_sampler,
                **loader_kwargs
            )
        }


class CarlaH5DatasetDynamic(Dataset):
    """
    åŠ¨æ€å¸§æ•°H5æ•°æ®é›†
    
    ç‰¹ç‚¹:
    - è‡ªåŠ¨æ£€æµ‹æ¯ä¸ªh5æ–‡ä»¶çš„å®é™…å¸§æ•°
    - æ”¯æŒä¸åŒå¸§æ•°çš„æ–‡ä»¶æ··åˆ
    - æ„å»ºå…¨å±€ç´¢å¼•æ˜ å°„è¡¨
    """
    def __init__(self, data_dir, train_eval_flag="train", use_cache=False, min_frames=10):
        self.data_dir = data_dir
        self.train_eval_flag = train_eval_flag
        self.use_cache = use_cache
        self.min_frames = min_frames
        
        # æŸ¥æ‰¾æ‰€æœ‰h5æ–‡ä»¶
        if not data_dir.endswith(('/', '\\')):
            data_dir = data_dir + '/'
        all_files = glob.glob(data_dir + '*.h5')
        all_files.sort()
        
        # æ‰«ææ¯ä¸ªæ–‡ä»¶çš„å¸§æ•°ï¼Œæ„å»ºç´¢å¼•æ˜ å°„
        self.data_list = []           # æœ‰æ•ˆçš„æ–‡ä»¶åˆ—è¡¨
        self.file_frames = []         # æ¯ä¸ªæ–‡ä»¶çš„å¸§æ•°
        self.cumulative_frames = [0]  # ç´¯ç§¯å¸§æ•°ï¼Œç”¨äºå¿«é€Ÿå®šä½
        
        print(f"ğŸ” æ‰«æ {len(all_files)} ä¸ªh5æ–‡ä»¶...")
        skipped = 0
        for file_path in all_files:
            try:
                with h5py.File(file_path, 'r') as f:
                    num_frames = f['rgb'].shape[0]
                    
                    # è·³è¿‡å¸§æ•°å¤ªå°‘çš„æ–‡ä»¶
                    if num_frames < min_frames:
                        skipped += 1
                        continue
                    
                    self.data_list.append(file_path)
                    self.file_frames.append(num_frames)
                    self.cumulative_frames.append(
                        self.cumulative_frames[-1] + num_frames
                    )
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡æŸåæ–‡ä»¶: {os.path.basename(file_path)} - {e}")
                skipped += 1
        
        self.total_frames = self.cumulative_frames[-1]
        
        if skipped > 0:
            print(f"âš ï¸ è·³è¿‡ {skipped} ä¸ªæ–‡ä»¶ (æŸåæˆ–å¸§æ•°<{min_frames})")
        
        if len(self.data_list) == 0:
            raise ValueError(f"âŒ ç›®å½• {data_dir} ä¸­æ²¡æœ‰æœ‰æ•ˆçš„h5æ–‡ä»¶!")
        
        # æ‰“å°å¸§æ•°ç»Ÿè®¡
        if self.file_frames:
            print(f"âœ… åŠ è½½ {len(self.data_list)} ä¸ªæ–‡ä»¶, å…± {self.total_frames} å¸§")
            print(f"   å¸§æ•°èŒƒå›´: {min(self.file_frames)} ~ {max(self.file_frames)}, "
                  f"å¹³å‡: {np.mean(self.file_frames):.1f}")
        
        # å†…å­˜ç¼“å­˜ (å¯é€‰)
        self._cache = {} if use_cache else None
        
        self.build_transform()

    def build_transform(self):
        if self.train_eval_flag == "train":
            self.transform = transforms.Compose([
                transforms.RandomOrder([
                    RandomTransWrapper(
                        seq=iaa.GaussianBlur((0, 1.5)),
                        p=0.09),
                    RandomTransWrapper(
                        seq=iaa.AdditiveGaussianNoise(
                            loc=0, scale=(0.0, 0.05), per_channel=0.5),
                        p=0.09),
                    RandomTransWrapper(
                        seq=iaa.Dropout((0.0, 0.10), per_channel=0.5),
                        p=0.3),
                    RandomTransWrapper(
                        seq=iaa.CoarseDropout(
                            (0.0, 0.10), size_percent=(0.08, 0.2), per_channel=0.5),
                        p=0.3),
                    RandomTransWrapper(
                        seq=iaa.Add((-20, 20), per_channel=0.5),
                        p=0.3),
                    RandomTransWrapper(
                        seq=iaa.Multiply((0.9, 1.1), per_channel=0.2),
                        p=0.4),
                    RandomTransWrapper(
                        seq=iaa.ContrastNormalization((0.8, 1.2), per_channel=0.5),
                        p=0.09),
                ]),
                transforms.ToTensor()])
        else:
            self.transform = transforms.Compose([transforms.ToTensor()])

    def __len__(self):
        return self.total_frames

    def _global_to_local(self, global_idx):
        """
        å°†å…¨å±€ç´¢å¼•è½¬æ¢ä¸º (æ–‡ä»¶ç´¢å¼•, æ–‡ä»¶å†…å¸§ç´¢å¼•)
        ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ï¼ŒO(log n) å¤æ‚åº¦
        """
        # äºŒåˆ†æŸ¥æ‰¾æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶
        left, right = 0, len(self.data_list) - 1
        while left < right:
            mid = (left + right + 1) // 2
            if self.cumulative_frames[mid] <= global_idx:
                left = mid
            else:
                right = mid - 1
        
        file_idx = left
        frame_idx = global_idx - self.cumulative_frames[file_idx]
        return file_idx, frame_idx

    def __getitem__(self, idx):
        # æ£€æŸ¥ç¼“å­˜
        if self._cache is not None and idx in self._cache:
            cached = self._cache[idx]
            img = self.transform(cached['img'].copy())
            return img, cached['speed'], cached['target'], cached['mask']
        
        # è½¬æ¢å…¨å±€ç´¢å¼•åˆ°å±€éƒ¨ç´¢å¼•
        file_idx, frame_idx = self._global_to_local(idx)
        file_name = self.data_list[file_idx]

        # è¯»å–æ•°æ®
        with h5py.File(file_name, 'r') as h5_file:
            img = np.array(h5_file['rgb'][frame_idx])
            target = np.array(h5_file['targets'][frame_idx]).astype(np.float32)
        
        # å¤„ç†å‘½ä»¤å’Œç›®æ ‡
        # 2 Follow lane, 3 Left, 4 Right, 5 Straight
        # -> 0 Follow lane, 1 Left, 2 Right, 3 Straight
        command = int(target[24]) - 2
        
        # ç¡®ä¿commandåœ¨æœ‰æ•ˆèŒƒå›´å†…
        command = max(0, min(3, command))
        
        target_vec = np.zeros((4, 3), dtype=np.float32)
        target_vec[command, :] = target[:3]  # Steer, Gas, Brake
        
        speed = np.array([target[10] / 25, ]).astype(np.float32)  # å½’ä¸€åŒ–é€Ÿåº¦
        
        mask_vec = np.zeros((4, 3), dtype=np.float32)
        mask_vec[command, :] = 1
        
        # ç¼“å­˜åŸå§‹æ•°æ®
        if self._cache is not None:
            self._cache[idx] = {
                'img': img,
                'speed': speed,
                'target': target_vec.reshape(-1),
                'mask': mask_vec.reshape(-1)
            }
        
        img = self.transform(img)
        return img, speed, target_vec.reshape(-1), mask_vec.reshape(-1)

    def get_file_info(self):
        """è¿”å›æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•"""
        return {
            'num_files': len(self.data_list),
            'total_frames': self.total_frames,
            'frames_per_file': self.file_frames,
            'min_frames': min(self.file_frames) if self.file_frames else 0,
            'max_frames': max(self.file_frames) if self.file_frames else 0,
            'avg_frames': np.mean(self.file_frames) if self.file_frames else 0,
        }
